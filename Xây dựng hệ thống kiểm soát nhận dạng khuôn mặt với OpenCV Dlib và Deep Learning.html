<!DOCTYPE html>
<!-- saved from url=(0113)https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3 -->
<html lang="en" data-n-head="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style type="text/css">.tippy-touch{cursor:pointer!important}.tippy-notransition{transition:none!important}.tippy-popper{max-width:350px;-webkit-perspective:700px;perspective:700px;z-index:9999;outline:0;transition-timing-function:cubic-bezier(.165,.84,.44,1);pointer-events:none;line-height:1.4}.tippy-popper[data-html]{max-width:96%;max-width:calc(100% - 20px)}.tippy-popper[x-placement^=top] .tippy-backdrop{border-radius:40% 40% 0 0}.tippy-popper[x-placement^=top] .tippy-roundarrow{bottom:-8px;-webkit-transform-origin:50% 0;transform-origin:50% 0}.tippy-popper[x-placement^=top] .tippy-roundarrow svg{position:absolute;left:0;-webkit-transform:rotate(180deg);transform:rotate(180deg)}.tippy-popper[x-placement^=top] .tippy-arrow{border-top:7px solid #333;border-right:7px solid transparent;border-left:7px solid transparent;bottom:-7px;margin:0 6px;-webkit-transform-origin:50% 0;transform-origin:50% 0}.tippy-popper[x-placement^=top] .tippy-backdrop{-webkit-transform-origin:0 90%;transform-origin:0 90%}.tippy-popper[x-placement^=top] .tippy-backdrop[data-state=visible]{-webkit-transform:scale(6) translate(-50%,25%);transform:scale(6) translate(-50%,25%);opacity:1}.tippy-popper[x-placement^=top] .tippy-backdrop[data-state=hidden]{-webkit-transform:scale(1) translate(-50%,25%);transform:scale(1) translate(-50%,25%);opacity:0}.tippy-popper[x-placement^=top] [data-animation=shift-toward][data-state=visible]{opacity:1;-webkit-transform:translateY(-10px);transform:translateY(-10px)}.tippy-popper[x-placement^=top] [data-animation=shift-toward][data-state=hidden]{opacity:0;-webkit-transform:translateY(-20px);transform:translateY(-20px)}.tippy-popper[x-placement^=top] [data-animation=perspective]{-webkit-transform-origin:bottom;transform-origin:bottom}.tippy-popper[x-placement^=top] [data-animation=perspective][data-state=visible]{opacity:1;-webkit-transform:translateY(-10px) rotateX(0);transform:translateY(-10px) rotateX(0)}.tippy-popper[x-placement^=top] [data-animation=perspective][data-state=hidden]{opacity:0;-webkit-transform:translateY(0) rotateX(90deg);transform:translateY(0) rotateX(90deg)}.tippy-popper[x-placement^=top] [data-animation=fade][data-state=visible]{opacity:1;-webkit-transform:translateY(-10px);transform:translateY(-10px)}.tippy-popper[x-placement^=top] [data-animation=fade][data-state=hidden]{opacity:0;-webkit-transform:translateY(-10px);transform:translateY(-10px)}.tippy-popper[x-placement^=top] [data-animation=shift-away][data-state=visible]{opacity:1;-webkit-transform:translateY(-10px);transform:translateY(-10px)}.tippy-popper[x-placement^=top] [data-animation=shift-away][data-state=hidden]{opacity:0;-webkit-transform:translateY(0);transform:translateY(0)}.tippy-popper[x-placement^=top] [data-animation=scale][data-state=visible]{opacity:1;-webkit-transform:translateY(-10px) scale(1);transform:translateY(-10px) scale(1)}.tippy-popper[x-placement^=top] [data-animation=scale][data-state=hidden]{opacity:0;-webkit-transform:translateY(0) scale(0);transform:translateY(0) scale(0)}.tippy-popper[x-placement^=bottom] .tippy-backdrop{border-radius:0 0 30% 30%}.tippy-popper[x-placement^=bottom] .tippy-roundarrow{top:-8px;-webkit-transform-origin:50% 100%;transform-origin:50% 100%}.tippy-popper[x-placement^=bottom] .tippy-roundarrow svg{position:absolute;left:0;-webkit-transform:rotate(0);transform:rotate(0)}.tippy-popper[x-placement^=bottom] .tippy-arrow{border-bottom:7px solid #333;border-right:7px solid transparent;border-left:7px solid transparent;top:-7px;margin:0 6px;-webkit-transform-origin:50% 100%;transform-origin:50% 100%}.tippy-popper[x-placement^=bottom] .tippy-backdrop{-webkit-transform-origin:0 -90%;transform-origin:0 -90%}.tippy-popper[x-placement^=bottom] .tippy-backdrop[data-state=visible]{-webkit-transform:scale(6) translate(-50%,-125%);transform:scale(6) translate(-50%,-125%);opacity:1}.tippy-popper[x-placement^=bottom] .tippy-backdrop[data-state=hidden]{-webkit-transform:scale(1) translate(-50%,-125%);transform:scale(1) translate(-50%,-125%);opacity:0}.tippy-popper[x-placement^=bottom] [data-animation=shift-toward][data-state=visible]{opacity:1;-webkit-transform:translateY(10px);transform:translateY(10px)}.tippy-popper[x-placement^=bottom] [data-animation=shift-toward][data-state=hidden]{opacity:0;-webkit-transform:translateY(20px);transform:translateY(20px)}.tippy-popper[x-placement^=bottom] [data-animation=perspective]{-webkit-transform-origin:top;transform-origin:top}.tippy-popper[x-placement^=bottom] [data-animation=perspective][data-state=visible]{opacity:1;-webkit-transform:translateY(10px) rotateX(0);transform:translateY(10px) rotateX(0)}.tippy-popper[x-placement^=bottom] [data-animation=perspective][data-state=hidden]{opacity:0;-webkit-transform:translateY(0) rotateX(-90deg);transform:translateY(0) rotateX(-90deg)}.tippy-popper[x-placement^=bottom] [data-animation=fade][data-state=visible]{opacity:1;-webkit-transform:translateY(10px);transform:translateY(10px)}.tippy-popper[x-placement^=bottom] [data-animation=fade][data-state=hidden]{opacity:0;-webkit-transform:translateY(10px);transform:translateY(10px)}.tippy-popper[x-placement^=bottom] [data-animation=shift-away][data-state=visible]{opacity:1;-webkit-transform:translateY(10px);transform:translateY(10px)}.tippy-popper[x-placement^=bottom] [data-animation=shift-away][data-state=hidden]{opacity:0;-webkit-transform:translateY(0);transform:translateY(0)}.tippy-popper[x-placement^=bottom] [data-animation=scale][data-state=visible]{opacity:1;-webkit-transform:translateY(10px) scale(1);transform:translateY(10px) scale(1)}.tippy-popper[x-placement^=bottom] [data-animation=scale][data-state=hidden]{opacity:0;-webkit-transform:translateY(0) scale(0);transform:translateY(0) scale(0)}.tippy-popper[x-placement^=left] .tippy-backdrop{border-radius:50% 0 0 50%}.tippy-popper[x-placement^=left] .tippy-roundarrow{right:-16px;-webkit-transform-origin:33.33333333% 50%;transform-origin:33.33333333% 50%}.tippy-popper[x-placement^=left] .tippy-roundarrow svg{position:absolute;left:0;-webkit-transform:rotate(90deg);transform:rotate(90deg)}.tippy-popper[x-placement^=left] .tippy-arrow{border-left:7px solid #333;border-top:7px solid transparent;border-bottom:7px solid transparent;right:-7px;margin:3px 0;-webkit-transform-origin:0 50%;transform-origin:0 50%}.tippy-popper[x-placement^=left] .tippy-backdrop{-webkit-transform-origin:100% 0;transform-origin:100% 0}.tippy-popper[x-placement^=left] .tippy-backdrop[data-state=visible]{-webkit-transform:scale(6) translate(40%,-50%);transform:scale(6) translate(40%,-50%);opacity:1}.tippy-popper[x-placement^=left] .tippy-backdrop[data-state=hidden]{-webkit-transform:scale(1.5) translate(40%,-50%);transform:scale(1.5) translate(40%,-50%);opacity:0}.tippy-popper[x-placement^=left] [data-animation=shift-toward][data-state=visible]{opacity:1;-webkit-transform:translateX(-10px);transform:translateX(-10px)}.tippy-popper[x-placement^=left] [data-animation=shift-toward][data-state=hidden]{opacity:0;-webkit-transform:translateX(-20px);transform:translateX(-20px)}.tippy-popper[x-placement^=left] [data-animation=perspective]{-webkit-transform-origin:right;transform-origin:right}.tippy-popper[x-placement^=left] [data-animation=perspective][data-state=visible]{opacity:1;-webkit-transform:translateX(-10px) rotateY(0);transform:translateX(-10px) rotateY(0)}.tippy-popper[x-placement^=left] [data-animation=perspective][data-state=hidden]{opacity:0;-webkit-transform:translateX(0) rotateY(-90deg);transform:translateX(0) rotateY(-90deg)}.tippy-popper[x-placement^=left] [data-animation=fade][data-state=visible]{opacity:1;-webkit-transform:translateX(-10px);transform:translateX(-10px)}.tippy-popper[x-placement^=left] [data-animation=fade][data-state=hidden]{opacity:0;-webkit-transform:translateX(-10px);transform:translateX(-10px)}.tippy-popper[x-placement^=left] [data-animation=shift-away][data-state=visible]{opacity:1;-webkit-transform:translateX(-10px);transform:translateX(-10px)}.tippy-popper[x-placement^=left] [data-animation=shift-away][data-state=hidden]{opacity:0;-webkit-transform:translateX(0);transform:translateX(0)}.tippy-popper[x-placement^=left] [data-animation=scale][data-state=visible]{opacity:1;-webkit-transform:translateX(-10px) scale(1);transform:translateX(-10px) scale(1)}.tippy-popper[x-placement^=left] [data-animation=scale][data-state=hidden]{opacity:0;-webkit-transform:translateX(0) scale(0);transform:translateX(0) scale(0)}.tippy-popper[x-placement^=right] .tippy-backdrop{border-radius:0 50% 50% 0}.tippy-popper[x-placement^=right] .tippy-roundarrow{left:-16px;-webkit-transform-origin:66.66666666% 50%;transform-origin:66.66666666% 50%}.tippy-popper[x-placement^=right] .tippy-roundarrow svg{position:absolute;left:0;-webkit-transform:rotate(-90deg);transform:rotate(-90deg)}.tippy-popper[x-placement^=right] .tippy-arrow{border-right:7px solid #333;border-top:7px solid transparent;border-bottom:7px solid transparent;left:-7px;margin:3px 0;-webkit-transform-origin:100% 50%;transform-origin:100% 50%}.tippy-popper[x-placement^=right] .tippy-backdrop{-webkit-transform-origin:-100% 0;transform-origin:-100% 0}.tippy-popper[x-placement^=right] .tippy-backdrop[data-state=visible]{-webkit-transform:scale(6) translate(-140%,-50%);transform:scale(6) translate(-140%,-50%);opacity:1}.tippy-popper[x-placement^=right] .tippy-backdrop[data-state=hidden]{-webkit-transform:scale(1.5) translate(-140%,-50%);transform:scale(1.5) translate(-140%,-50%);opacity:0}.tippy-popper[x-placement^=right] [data-animation=shift-toward][data-state=visible]{opacity:1;-webkit-transform:translateX(10px);transform:translateX(10px)}.tippy-popper[x-placement^=right] [data-animation=shift-toward][data-state=hidden]{opacity:0;-webkit-transform:translateX(20px);transform:translateX(20px)}.tippy-popper[x-placement^=right] [data-animation=perspective]{-webkit-transform-origin:left;transform-origin:left}.tippy-popper[x-placement^=right] [data-animation=perspective][data-state=visible]{opacity:1;-webkit-transform:translateX(10px) rotateY(0);transform:translateX(10px) rotateY(0)}.tippy-popper[x-placement^=right] [data-animation=perspective][data-state=hidden]{opacity:0;-webkit-transform:translateX(0) rotateY(90deg);transform:translateX(0) rotateY(90deg)}.tippy-popper[x-placement^=right] [data-animation=fade][data-state=visible]{opacity:1;-webkit-transform:translateX(10px);transform:translateX(10px)}.tippy-popper[x-placement^=right] [data-animation=fade][data-state=hidden]{opacity:0;-webkit-transform:translateX(10px);transform:translateX(10px)}.tippy-popper[x-placement^=right] [data-animation=shift-away][data-state=visible]{opacity:1;-webkit-transform:translateX(10px);transform:translateX(10px)}.tippy-popper[x-placement^=right] [data-animation=shift-away][data-state=hidden]{opacity:0;-webkit-transform:translateX(0);transform:translateX(0)}.tippy-popper[x-placement^=right] [data-animation=scale][data-state=visible]{opacity:1;-webkit-transform:translateX(10px) scale(1);transform:translateX(10px) scale(1)}.tippy-popper[x-placement^=right] [data-animation=scale][data-state=hidden]{opacity:0;-webkit-transform:translateX(0) scale(0);transform:translateX(0) scale(0)}.tippy-tooltip{position:relative;color:#fff;border-radius:4px;font-size:.9rem;padding:.3rem .6rem;text-align:center;will-change:transform;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;background-color:#333}.tippy-tooltip[data-size=small]{padding:.2rem .4rem;font-size:.75rem}.tippy-tooltip[data-size=large]{padding:.4rem .8rem;font-size:1rem}.tippy-tooltip[data-animatefill]{overflow:hidden;background-color:transparent}.tippy-tooltip[data-animatefill] .tippy-content{transition:-webkit-clip-path cubic-bezier(.46,.1,.52,.98);transition:clip-path cubic-bezier(.46,.1,.52,.98);transition:clip-path cubic-bezier(.46,.1,.52,.98),-webkit-clip-path cubic-bezier(.46,.1,.52,.98)}.tippy-tooltip[data-interactive],.tippy-tooltip[data-interactive] path{pointer-events:auto}.tippy-tooltip[data-inertia][data-state=visible]{transition-timing-function:cubic-bezier(.53,2,.36,.85)}.tippy-tooltip[data-inertia][data-state=hidden]{transition-timing-function:ease}.tippy-arrow,.tippy-roundarrow{position:absolute;width:0;height:0}.tippy-roundarrow{width:24px;height:8px;fill:#333;pointer-events:none}.tippy-backdrop{position:absolute;will-change:transform;background-color:#333;border-radius:50%;width:26%;left:50%;top:50%;z-index:-1;transition:all cubic-bezier(.46,.1,.52,.98);-webkit-backface-visibility:hidden;backface-visibility:hidden}.tippy-backdrop:after{content:"";float:left;padding-top:100%}body:not(.tippy-touch) .tippy-tooltip[data-animatefill][data-state=visible] .tippy-content{-webkit-clip-path:ellipse(100% 100% at 50% 50%);clip-path:ellipse(100% 100% at 50% 50%)}body:not(.tippy-touch) .tippy-tooltip[data-animatefill][data-state=hidden] .tippy-content{-webkit-clip-path:ellipse(5% 50% at 50% 50%);clip-path:ellipse(5% 50% at 50% 50%)}body:not(.tippy-touch) .tippy-popper[x-placement=right] .tippy-tooltip[data-animatefill][data-state=visible] .tippy-content{-webkit-clip-path:ellipse(135% 100% at 0 50%);clip-path:ellipse(135% 100% at 0 50%)}body:not(.tippy-touch) .tippy-popper[x-placement=right] .tippy-tooltip[data-animatefill][data-state=hidden] .tippy-content{-webkit-clip-path:ellipse(40% 100% at 0 50%);clip-path:ellipse(40% 100% at 0 50%)}body:not(.tippy-touch) .tippy-popper[x-placement=left] .tippy-tooltip[data-animatefill][data-state=visible] .tippy-content{-webkit-clip-path:ellipse(135% 100% at 100% 50%);clip-path:ellipse(135% 100% at 100% 50%)}body:not(.tippy-touch) .tippy-popper[x-placement=left] .tippy-tooltip[data-animatefill][data-state=hidden] .tippy-content{-webkit-clip-path:ellipse(40% 100% at 100% 50%);clip-path:ellipse(40% 100% at 100% 50%)}@media (max-width:360px){.tippy-popper{max-width:96%;max-width:calc(100% - 20px)}}</style>
    <title>Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning</title><meta data-n-head="ssr" name="viewport" content="width=device-width, initial-scale=1"><meta data-n-head="ssr" http-equiv="X-UA-Compatible" content="IE=edge"><meta data-n-head="ssr" name="application-name" content="Viblo"><meta data-n-head="ssr" property="og:site_name" content="Viblo"><meta data-n-head="ssr" data-hid="fb:app_id" property="fb:app_id" content="313981178804207"><meta data-n-head="ssr" name="google-site-verification" content="RKTOz1S8uxhAZHqaOsf6cSvT_pqnPHEyAnlTnlLiiok"><meta data-n-head="ssr" name="dmca-site-verification" content="U3I1Yy84OGp3ZFprUTZCU1JrbjM4UT090"><meta data-n-head="ssr" name="msapplication-TileColor" content="#FFFFFF"><meta data-n-head="ssr" name="msapplication-TileImage" content="/mstile-144x144.png"><meta data-n-head="ssr" name="msapplication-square70x70logo" content="/mstile-70x70.png"><meta data-n-head="ssr" name="msapplication-square150x150logo" content="/mstile-150x150.png"><meta data-n-head="ssr" name="msapplication-wide310x150logo" content="/mstile-310x150.png"><meta data-n-head="ssr" name="msapplication-square310x310logo" content="/mstile-310x310.png"><meta data-n-head="ssr" data-hid="mobile-web-app-capable" name="mobile-web-app-capable" content="yes"><meta data-n-head="ssr" data-hid="apple-mobile-web-app-title" name="apple-mobile-web-app-title" content="Viblo"><meta data-n-head="ssr" data-hid="theme-color" name="theme-color" content="#5488c7"><meta data-n-head="ssr" data-hid="og:type" property="og:type" content="article"><meta data-n-head="ssr" data-hid="og:url" property="og:url" content="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3"><meta data-n-head="ssr" data-hid="og:site_name" property="og:site_name" content="Viblo"><meta data-n-head="ssr" data-hid="og:title" property="og:title" content="Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning"><meta data-n-head="ssr" data-hid="keywords" name="keywords" content="Machine Learning, Deep Learning, Open CV"><meta data-n-head="ssr" data-hid="article:published_time" name="article:published_time" content="2018-12-10T22:22:54+07:00"><meta data-n-head="ssr" data-hid="article:modified_time" name="article:modified_time" content="2021-10-13T19:00:01+07:00"><meta data-n-head="ssr" data-hid="article:author" name="article:author" content="https://viblo.asia/u/hoanganhpham"><meta data-n-head="ssr" data-hid="article:tag" name="article:tag" content="Machine Learning, Deep Learning, Open CV"><meta data-n-head="ssr" data-hid="twitter:title" name="twitter:title" content="Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning"><meta data-n-head="ssr" data-hid="twitter:description" name="twitter:description" content="Hệ thống kiểm soát nhận dạng khuôn mặt là gì?"><meta data-n-head="ssr" data-hid="twitter:card" name="twitter:card" content="summary"><meta data-n-head="ssr" data-hid="robots" name="robots" content="index,follow"><meta data-n-head="ssr" data-hid="og:image" property="og:image" content="https://images.viblo.asia/1c2afe28-51e3-419e-b038-3340593e56a0.jpg"><meta data-n-head="ssr" data-hid="description" name="description" content="Hệ thống kiểm soát nhận dạng khuôn mặt là gì?"><meta data-n-head="ssr" data-hid="og:description" property="og:description" content="Hệ thống kiểm soát nhận dạng khuôn mặt là gì?"><link data-n-head="ssr" rel="alternate" type="application/rss+xml" name="Viblo RSS Feed" href="https://viblo.asia/rss"><link data-n-head="ssr" rel="preconnect" href="https://fonts.googleapis.com/"><link data-n-head="ssr" rel="preconnect" href="https://fonts.gstatic.com/" crossorigin=""><link data-n-head="ssr" rel="stylesheet" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/css2"><link data-n-head="ssr" rel="stylesheet" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous"><link data-n-head="ssr" rel="icon" type="image/x-icon" href="https://viblo.asia/favicon.ico"><link data-n-head="ssr" rel="apple-touch-icon-precomposed" sizes="57x57" href="https://viblo.asia/apple-touch-icon-57x57.png"><link data-n-head="ssr" rel="apple-touch-icon-precomposed" sizes="114x114" href="https://viblo.asia/apple-touch-icon-114x114.png"><link data-n-head="ssr" rel="apple-touch-icon-precomposed" sizes="72x72" href="https://viblo.asia/apple-touch-icon-72x72.png"><link data-n-head="ssr" rel="apple-touch-icon-precomposed" sizes="144x144" href="https://viblo.asia/apple-touch-icon-144x144.png"><link data-n-head="ssr" rel="apple-touch-icon-precomposed" sizes="60x60" href="https://viblo.asia/apple-touch-icon-60x60.png"><link data-n-head="ssr" rel="apple-touch-icon-precomposed" sizes="120x120" href="https://viblo.asia/apple-touch-icon-120x120.png"><link data-n-head="ssr" rel="apple-touch-icon-precomposed" sizes="76x76" href="https://viblo.asia/apple-touch-icon-76x76.png"><link data-n-head="ssr" rel="apple-touch-icon-precomposed" sizes="152x152" href="https://viblo.asia/apple-touch-icon-152x152.png"><link data-n-head="ssr" rel="icon" type="image/png" href="https://viblo.asia/favicon-196x196.png" sizes="196x196"><link data-n-head="ssr" rel="icon" type="image/png" href="https://viblo.asia/favicon-96x96.png" sizes="96x96"><link data-n-head="ssr" rel="icon" type="image/png" href="https://viblo.asia/favicon-32x32.png" sizes="32x32"><link data-n-head="ssr" rel="icon" type="image/png" href="https://viblo.asia/favicon-16x16.png" sizes="16x16"><link data-n-head="ssr" rel="icon" type="image/png" href="https://viblo.asia/favicon-128.png" sizes="128x128"><link data-n-head="ssr" data-hid="shortcut-icon" rel="shortcut icon" href="https://viblo.asia/_nuxt/icons/icon_64x64.a0a65a.png"><link data-n-head="ssr" data-hid="apple-touch-icon" rel="apple-touch-icon" href="https://viblo.asia/_nuxt/icons/icon_512x512.a0a65a.png" sizes="512x512"><link data-n-head="ssr" rel="manifest" href="https://viblo.asia/_nuxt/manifest.01f43339.json" data-hid="manifest" crossorigin="use-credentials"><link data-n-head="ssr" data-hid="canonical" rel="canonical" href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3"><script data-n-head="ssr" type="application/ld+json">{"@context":"https://schema.org","@type":"Article","image":["https://images.viblo.asia/1c2afe28-51e3-419e-b038-3340593e56a0.jpg","https://images.viblo.asia/1c2afe28-51e3-419e-b038-3340593e56a0.jpg"],"author":{"@type":"Person","name":"Phạm Hoàng Anh","@id":"https://viblo.asia/u/hoanganhpham","url":"https://viblo.asia/u/hoanganhpham"},"keywords":"Machine Learning, Deep Learning, Open CV","headline":"Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning","url":"https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3","mainEntityOfPage":{"@type":"WebPage","@id":"https://viblo.asia/newest"},"publisher":{"@type":"Organization","name":"Sun* AI Research Team","logo":{"@type":"ImageObject","url":"https://images.viblo.asia/c2739118-a46f-4c47-96ba-c7e8a4781b18.jpg"},"sameAs":null},"datePublished":"2018-12-10T15:22:54.000Z","dateCreated":"2018-12-05T15:40:03.000Z","dateModified":"2021-10-13T12:00:01.000Z","description":"Hệ thống kiểm soát nhận dạng khuôn mặt là gì?","articleBody":"Hệ thống kiểm soát nhận dạng khuôn mặt là gì?"}</script><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/runtime.136d1f46ed0e13831702.js.download" as="script"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/survey.0130766880e9f0519853.css" as="style"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/survey.f6c052afb455459f7605.js.download" as="script"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/emails.2bc5ead1b3f183186911.css" as="style"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/emails.c5ceecef337df1a2df63.js.download" as="script"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/app.fa115282404a02948313.css" as="style"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/app.6b57972a9b98a8f6b6cb.js.download" as="script"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/content_view.9764fb9e2719adb8df1a.css" as="style"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/content_view.7b9480c7796dcc2542c4.js.download" as="script"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/user.f8db055cc5addbe5c1fd.js.download" as="script"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/settings.f3db95e19baabb5dc926.css" as="style"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/settings.9d3e8fd3a6bae05d0c8f.js.download" as="script"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/user.53e115bf07e63b6c96f3.js.download" as="script"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/user.d61fd099ac16c85a6228.js.download" as="script"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/index.a708958c9fe48622d123.css" as="style"><link rel="preload" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/index.0678f564d2df3141d3c4.js.download" as="script"><link rel="stylesheet" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/survey.0130766880e9f0519853.css"><link rel="stylesheet" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/emails.2bc5ead1b3f183186911.css"><link rel="stylesheet" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/app.fa115282404a02948313.css"><link rel="stylesheet" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/content_view.9764fb9e2719adb8df1a.css"><link rel="stylesheet" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/settings.f3db95e19baabb5dc926.css"><link rel="stylesheet" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/index.a708958c9fe48622d123.css">
  <style type="text/css">.medium-zoom-overlay{position:fixed;top:0;right:0;bottom:0;left:0;opacity:0;transition:opacity .3s;will-change:opacity}.medium-zoom--opened .medium-zoom-overlay{cursor:pointer;cursor:zoom-out;opacity:1}.medium-zoom-image{cursor:pointer;cursor:zoom-in;transition:transform .3s cubic-bezier(.2,0,.2,1)!important}.medium-zoom-image--hidden{visibility:hidden}.medium-zoom-image--opened{position:relative;cursor:pointer;cursor:zoom-out;will-change:transform}</style><script type="text/javascript" charset="utf8" async="" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/analytics.js.download"></script><script type="text/javascript" charset="utf8" async="" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/client" defer=""></script><link rel="preload" as="style" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/organizations.1dd77d2394bd45d95cea.css"><script charset="utf-8" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/organizations.6e8166ed63d5ea32f757.js.download"></script><link rel="preload" as="style" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/user.73496136fc797cdf104c.css"><script charset="utf-8" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/user.078844b48ab7631f7ca2.js.download"></script><link rel="preload" as="style" href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/index.614d9314499953f2515e.css"><script charset="utf-8" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/index.96319866e0f7bed1db4e.js.download"></script><script charset="utf-8" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/review-contents.18ba66927a4a450f0892.js.download"></script></head>
  <body>
    <div id="__nuxt"><div class="progress" style="width:0%;height:2px;background-color:#5488c7;opacity:0;" data-v-4e3e2ebc=""></div><div id="__layout"><div id="app-container" class="default"><header class="main-navbar main-navbar__group py-1"><div class="main-navbar__container container px-md-0"><div class="main-navbar__left"><a href="https://viblo.asia/newest" class="main-navbar__logo d-block mr-lg-5"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/logo_full.svg" alt="Viblo" width="62" height="21"></a> <ul class="main-menu list-unstyled hidden-md-down"><li class="main-menu__item"><a href="https://viblo.asia/newest" class="link">
            Bài Viết
        </a></li> <li id="v-step-2" class="main-menu__item"><div class=""><a href="https://viblo.asia/questions" class="link"><div class="el-badge badge-has-new">
                    Hỏi Đáp
                <sup class="el-badge__content el-badge__content--undefined is-fixed" style="display:none;"></sup></div></a></div></li> <li class="main-menu__item"><a href="https://viblo.asia/discussion" class="link">
            Thảo Luận
        </a></li></ul></div> <div class="main-navbar__right"><a href="https://viblo.asia/search" class="link text-muted hidden-md-up mr-1"><i aria-hidden="true" class="fa fa-search"></i></a> <div class="sb hidden-sm-down flex-fill mr-1"><input placeholder="Tìm kiếm trên Viblo" value="" class="sb__input"> <button class="btn btn-primary" style="display:;"><i class="fa fa-search"></i></button> <i aria-hidden="true" class="fa fa-circle-o-notch fa-spin sb-icon" style="display:none;"></i> <i aria-hidden="true" class="fa fa-times sb-icon clr text-muted" style="display:none;"></i> <div class="sb__suggestions" style="display:none;"><div></div></div></div> <div class="main-navbar__group"><span class="flyout announcement-flyout mr-1"><div role="tooltip" id="el-popover-7" aria-hidden="true" class="el-popover el-popper flyout__popper" style="width:undefinedpx;display:none;" tabindex="0"><!----> <div class="flyout__header"><div class="d-flex align-items-center justify-content-between"><span class="text-dark">Thông tin</span> <!----></div></div> <div class="flyout__body"><div class="flyout__scroll el-scrollbar"><div class="flyout__scroll-wrap el-scrollbar__wrap" style="margin-bottom: -17px; margin-right: -17px;"><div class="el-scrollbar__view"> <div class="py-05 text-center"><span><i aria-hidden="true" class="fa fa-times"></i> Chưa có thông tin
        </span></div> </div></div><div class="el-scrollbar__bar is-horizontal"><div class="el-scrollbar__thumb" style="transform: translateX(0%);"></div></div><div class="el-scrollbar__bar is-vertical"><div class="el-scrollbar__thumb" style="transform: translateY(0%);"></div></div></div></div> <div class="flyout__footer"><div class="text-right"><a href="https://viblo.asia/announcements" class="announcement-flyout__all">
            Tất cả thông tin
        </a></div></div></div><span class="el-popover__reference-wrapper"><div class="el-badge el-popover__reference" aria-describedby="el-popover-7" tabindex="0"><button type="button" class="el-button text-muted el-button--text"><!----><i class="fa fa-info"></i><!----></button> <!----></div></span></span> <!----></div> <div class="main-navbar__group"><div class="mr-1"><!----></div> <button type="button" class="el-button el-button--text"><!----><i class="fa fa-sign-in"></i><span>
    Đăng nhập/Đăng ký
</span></button> <!----></div> <!----></div></div> <!----></header> <div id="main-content"><div class="default"><div class="v-ctr-section promo__banner"><a href="https://ctf.viblo.asia/" aria-ctr-enable="Viblo CTF" target="_blank" rel="noopener"><div style="background-color:#4878bf;"><div class="container px-0"><div class="pil-wrapper"><canvas width="1140" height="168" class="pil-placeholder"></canvas> <div class="pil-tiny-wrapper pil-loaded"><img alt="Viblo CTF" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/f6e3d256-a4d4-4751-8fc6-895e53f6c74f.jpg" width="1140" height="168" class="pil-tiny-img"></div> <div class="pil-original-wrapper pil-loaded"><img alt="Viblo CTF" data-pil-src="https://images.viblo.asia/full/f6e3d256-a4d4-4751-8fc6-895e53f6c74f.jpg" width="1140" height="168" class="pil-original-img" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/f6e3d256-a4d4-4751-8fc6-895e53f6c74f(1).jpg"></div></div></div></div></a></div> <!----> <div class="container py-2"><div class="screen-default"><div class="hidden-md-down post-action"><div class="post-actions d-flex flex-column align-items-center mx-auto"><!----> <div class="votes votes--side post-actions__vote mb-1"><button class="icon-btn vote" data-tippy="" data-original-title="Upvote"><i aria-hidden="true" class="fa fa-caret-up"></i></button> <div class="points text-muted">
        +29
    </div> <button class="icon-btn vote" data-tippy="" data-original-title="Downvote"><i aria-hidden="true" class="fa fa-caret-down"></i></button></div> <div class="subscribe mb-2" data-v-e2f1134c=""><button type="button" class="el-button post-actions__clip el-button--default" data-v-e2f1134c="" data-tippy="" data-original-title="Bookmark bài viết này"><!----><i class="fa fa-bookmark"></i><!----></button></div> <span class="mb-2" data-v-ff3977b0="" data-v-5dedd11a=""><div role="tooltip" id="el-popover-7237" aria-hidden="true" class="el-popover el-popper" style="width:undefinedpx;display:none;" tabindex="0"><!----><div class="type-control-options" data-v-ff3977b0=""><div data-v-ff3977b0=""><i class="fa fa-font control-icon" data-v-ff3977b0=""></i> <span data-v-ff3977b0="">Cỡ chữ</span></div> <div data-v-ff3977b0=""><button type="button" class="el-button button-modify el-button--default el-button--mini is-circle" data-v-ff3977b0=""><!----><!----><span><i class="fa fa-minus" data-v-ff3977b0=""></i></span></button> <span class="control-info" data-v-ff3977b0="">18px</span> <button type="button" class="el-button button-modify el-button--default el-button--mini is-circle" data-v-ff3977b0=""><!----><!----><span><i class="fa fa-plus" data-v-ff3977b0=""></i></span></button></div> <div data-v-ff3977b0=""><i class="fa fa-text-height control-icon" data-v-ff3977b0=""></i> <span data-v-ff3977b0="">Độ cao hàng</span></div> <div data-v-ff3977b0=""><button type="button" class="el-button button-modify el-button--default el-button--mini is-circle" data-v-ff3977b0=""><!----><!----><span><i class="fa fa-minus" data-v-ff3977b0=""></i></span></button> <span class="control-info" data-v-ff3977b0="">1.75</span> <button type="button" class="el-button button-modify el-button--default el-button--mini is-circle" data-v-ff3977b0=""><!----><!----><span><i class="fa fa-plus" data-v-ff3977b0=""></i></span></button></div></div> <div class="d-flex mode-theme mt-1" data-v-ff3977b0=""><div role="radiogroup" class="el-radio-group" data-v-ff3977b0=""><label role="radio" tabindex="-1" class="el-radio-button" data-v-ff3977b0=""><input type="radio" tabindex="-1" value="false" checked="checked" class="el-radio-button__orig-radio"><span class="el-radio-button__inner">
                Mặc định
            <!----></span></label> <label role="radio" tabindex="-1" class="el-radio-button" data-v-ff3977b0=""><input type="radio" tabindex="-1" value="true" class="el-radio-button__orig-radio"><span class="el-radio-button__inner">
                Toàn màn hình
            <!----></span></label></div></div> <div class="d-flex mode-theme mt-1" data-v-ff3977b0=""><p data-v-ff3977b0="">
            Màu nền
        </p> <p class="color-mode color-white background-button-mode" data-v-ff3977b0=""></p> <p class="color-mode color-dark" data-v-ff3977b0=""></p> <p class="color-mode color-sepia" data-v-ff3977b0=""></p></div> <div class="reset-default mt-1" data-v-ff3977b0=""><button type="button" class="el-button button-reset el-button--default el-button--mini" data-v-ff3977b0=""><!----><!----><span>
            Đặt lại
        </span></button></div> </div><span class="el-popover__reference-wrapper"><button type="button" class="el-button is-circle type-control el-button--default el-popover__reference" data-v-5dedd11a="" aria-describedby="el-popover-7237" tabindex="0"><!----><!----><span><i class="fa fa-font" data-v-5dedd11a=""></i></span></button></span></span> <div class="social-sharing mb-2 social-sharing--horizontal social-sharing--small" data-v-92417f3e=""><a tooltip-placement="right" rel="noopener" class="link link--muted link--muted" data-v-92417f3e="" data-tippy="" data-original-title="Chia sẻ liên kết đến trang này trên Facebook"><i aria-hidden="true" class="fa fa-facebook" data-v-92417f3e=""></i></a> <a tooltip-placement="right" rel="noopener" class="link link--muted link--muted" data-v-92417f3e="" data-tippy="" data-original-title="Chia sẻ liên kết đến trang này trên Twitter"><i aria-hidden="true" class="fa fa-twitter" data-v-92417f3e=""></i></a></div> <!----> <!----></div> <!----></div> <div class="post-body__main post-content"><article class="post-content"><header class="mb-05"><div class="d-sm-flex align-items-start mb-2"><div class="post-author mb-2 mb-sm-0"><a href="https://viblo.asia/u/hoanganhpham" class="d-flex mr-05"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/f4849a25-3687-49cb-ab03-53c9597435f0.jpg" srcset="https://images.viblo.asia/avatar-retina/f4849a25-3687-49cb-ab03-53c9597435f0.jpg 2x" alt="Avatar" class="avatar avatar--lg" data-v-5e990434=""></a> <div class="post-author__info overflow-hidden mr-1"><div class="d-flex"><div class="overflow-hidden flex-fix mr-05"><a href="https://viblo.asia/u/hoanganhpham" class="text-bold post-author__name">
                    Phạm Hoàng Anh
                </a> <span class="text-muted">@hoanganhpham</span></div> <div class="subscribe"><button type="button" class="el-button el-button--mini-mini is-plain"><!----><!----><span>
                    Theo dõi
                </span></button></div></div> <div class="stats"><span class="stats-item text-muted" data-tippy="" data-original-title="Reputations: 3200"><i aria-hidden="true" class="stats-item__icon fa fa-star"></i>
        3.2K
    </span><span class="stats-item text-muted" data-tippy="" data-original-title="Người theo dõi: 211"><i aria-hidden="true" class="stats-item__icon fa fa-user-plus"></i>
        211
    </span><span class="stats-item text-muted" data-tippy="" data-original-title="Bài viết: 15"><i aria-hidden="true" class="stats-item__icon fa fa-pencil"></i>
        15
    </span> </div></div></div> <div class="post-meta d-flex flex-column flex-wrap align-items-sm-end"><div class="text-muted">
            Đã đăng vào thg 12 10, 2018 10:22 PM
         <div class="d-inline"><span>trong</span> <span class="el-popover__title"><div role="tooltip" id="el-popover-5251" aria-hidden="true" class="el-popover el-popper" style="width:300px;display:none;" tabindex="0"><div class="el-popover__title">Sun* AI Research Team</div> <div class="d-flex justify-content-between"><p class="text-left">
                    We're AI Research Team of R&amp;D Lab @Sun Asterisk .Inc
                </p> <a href="https://viblo.asia/o/sun-ai-research-team" class="d-flex"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/c2739118-a46f-4c47-96ba-c7e8a4781b18.jpg" srcset="https://images.viblo.asia/thumbnail-retina/c2739118-a46f-4c47-96ba-c7e8a4781b18.jpg 2x" alt="Avatar" class="avatar avatar--lg avatar--rect avatar--ognzt" data-v-5e990434=""></a></div> <div class="d-flex justify-content-between align-items-center border-top mt-1 pt-05"><div>
                    Theo dõi bởi
                    <span class="text-body">520</span>
                    người.
                </div> <div class="subscribe"><button class="btn btn-follow">
                        Theo dõi
                    </button></div></div></div><span class="el-popover__reference-wrapper"><a href="https://viblo.asia/o/sun-ai-research-team" class="organization-name el-popover__reference" aria-describedby="el-popover-5251" tabindex="0">
            Sun* AI Research Team
        </a></span></span></div> <span title="22phút đọc" class="post-reading_time is-divide is-divide--fit text-muted">
    22 phút đọc
</span></div> <div class="d-flex align-items-center"><div class="post-meta__item mr-1 text-muted" data-tippy="" data-original-title="Lượt xem: 20179"><i aria-hidden="true" class="el-icon-view post-meta__icon"></i> <span>20.1K</span></div> <div class="post-meta__item mr-1 text-muted" data-tippy="" data-original-title="Di chuyển đến bình luận"><button type="button" class="el-button el-button--text"><!----><i class="fa fa-comments-o post-meta__icon"></i><span>
                45
            </span></button></div> <div class="post-meta__item text-muted" data-tippy="" data-original-title="Xem danh sách người bookmark"><button type="button" class="el-button el-button--text"><!----><i class="fa fa-bookmark post-meta__icon"></i><span>
                21
            </span></button></div> <!----></div></div></div> <h1 class="article-content__title">
            Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning
        </h1> <!----></header> <div class="d-md-flex align-items-top justify-content-between"><div class="tags" data-v-190ce5c0="">  </div> <div class="post__menu"><div class="el-dropdown"><button type="button" class="el-button p-0 el-button--text text-muted el-dropdown-selfdefine" data-tippy="" data-original-title="Hiển thị các hành động" aria-haspopup="list" aria-controls="dropdown-menu-2306" role="button" tabindex="0"><!----><i class="post__menu__more el-icon-more-outline"></i><!----></button> <ul class="el-dropdown-menu el-popper el-dropdown-menu--medium" style="display:none;" id="dropdown-menu-2306"><!----> <li tabindex="-1" class="el-dropdown-menu__item"><!----><i aria-hidden="true" class="fa fa-flag-o pr-0 mr-05"></i>
                Báo cáo
            </li> <!----> <!----> <!----> <!----> <!----> <!----> <!----></ul></div> <!----> <!----> <!----> <!----></div></div> <!----> <div><div role="alert" class="el-alert mt-1 el-alert--warning is-light"><i class="el-alert__icon el-icon-warning is-big"></i><div class="el-alert__content"><!----><p class="el-alert__description">
            Bài đăng này đã không được cập nhật trong 2 năm
        </p><!----><i class="el-alert__closebtn el-icon-close"></i></div></div></div> <div class="md-contents article-content__body my-2 flex-fill" style="font-size:18px;line-height:1.75;"><h1 id="_he-thong-kiem-soat-nhan-dang-khuon-mat-la-gi-0">Hệ thống kiểm soát nhận dạng khuôn mặt là gì?</h1>
<p></p><div class="pil-wrapper"><canvas class="pil-placeholder" width="580" height="325"></canvas><div class="pil-tiny-wrapper"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/1c2afe28-51e3-419e-b038-3340593e56a0.jpg" class="pil-tiny-img" width="580" height="325"></div><div class="pil-original-wrapper"><img data-pil-src="https://images.viblo.asia/1c2afe28-51e3-419e-b038-3340593e56a0.jpg" class="pil-original-img article-img medium-zoom-image" width="580" height="325" data-pil-srcset="https://images.viblo.asia/retina/1c2afe28-51e3-419e-b038-3340593e56a0.jpg 2x" data-zoom-src="https://images.viblo.asia/full/1c2afe28-51e3-419e-b038-3340593e56a0.jpg"></div></div><p></p>
<p>Vào thời điểm mình viết bài viết này, chắc hẳn cụm từ <strong>NHẬN DẠNG KHUÔN MẶT (FACIAL RECOGNITION)</strong> đã không còn là một khái niệm quá xa lạ đối với bất kỳ một ai. Đây là một kỹ thuật nhằm xác định một người từ một hình ảnh hoặc một khung hình trong video lấy được. Công nghệ nhận diện khuôn mặt giờ đã trở nên rất quen thuộc, và được áp dụng phổ biến trong các hệ thống an ninh ở nhiều nơi trên thế giới, trong đó có cả Việt Nam.</p>
<p>Ưu điểm của công nghệ này so với các công nghệ nhận dạng khác (nhận dạng vân tay, nhận dạng giọng nói, nhận dạng mống mắt) chính là việc <strong>nó không đòi hỏi sự hợp tác đến từ người dùng</strong>.</p>
<br>
<h1 id="_muc-tieu-1">Mục tiêu</h1>
<p>Hiện nay có rất nhiều kỹ thuật để thực hiện việc nhận dạng khuôn mặt, tuy nhiên điểm chung của các kỹ thuật này là đều sẽ phải thực hiện qua 3 bước:</p>
<ol>
<li>Xác định và lấy ra (các) khuôn mặt có trong hình ảnh</li>
<li>Từ hình ảnh các khuôn mặt lấy ra từ bước 1, thực hiện việc phân tích, trích xuất các đặt trưng của khuôn mặt</li>
<li>Từ các thông tin có được sau khi phân tích, kết luận và xác minh danh tính người dùng</li>
</ol>
<p>Thông qua bài viết lần này, mình sẽ xây dựng một hệ thống hoàn chỉnh cho việc nhận dạng khuôn mặt dựa vào thư viện Dlib của OpenCV và mạng Deep Learning sử dụng hàm Triplet Loss. Hy vọng sẽ giúp các bạn nắm được công nghệ này để có thể tự triển khai được trong thực tế.</p>
<h1 id="_xay-dung-he-thong-nhan-dang-khuon-mat-2">Xây dựng hệ thống nhận dạng khuôn mặt</h1>
<p>Một chút đọc lại trong phần ngay trước, mình đã nói về 3 bước thực hiện của một hệ thống nhận dạng khuôn mặt, và giờ chúng ta sẽ thực hiện đầy đủ 3 bước đó nhé.</p>
<h2 id="_xac-dinh-khuon-mat-trong-anh-facial-detection---viec-kho-da-co-dlib-lo-3">Xác định khuôn mặt trong ảnh (Facial detection) - Việc khó đã có Dlib lo</h2>
<p></p><div class="pil-wrapper"><canvas class="pil-placeholder" width="800" height="600"></canvas><div class="pil-tiny-wrapper"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/d3c5f6e9-cd20-4004-9d5f-5d18c821f0b7.jpg" class="pil-tiny-img" width="800" height="600"></div><div class="pil-original-wrapper"><img data-pil-src="https://images.viblo.asia/d3c5f6e9-cd20-4004-9d5f-5d18c821f0b7.jpg" class="pil-original-img article-img medium-zoom-image" width="800" height="600" data-pil-srcset="https://images.viblo.asia/retina/d3c5f6e9-cd20-4004-9d5f-5d18c821f0b7.jpg 2x" data-zoom-src="https://images.viblo.asia/full/d3c5f6e9-cd20-4004-9d5f-5d18c821f0b7.jpg"></div></div>
Điều cần làm đầu tiên với bức ảnh/ khung hình chúng ta có đó chính là xác định xem trong bức ảnh/ khung hình đó có sự xuất hiện của bao người khuôn mặt (bao nhiêu người) và vị trí của chúng trong bức ảnh. Bài toán trở nên rất giống với bài toán xác định vật thể (Object Detection). Đây là một trong những bài toán rất khó bởi chúng ta sẽ cần nhiều kinh nghiệm cũng như lý thuyết về xử lý ảnh để có thể giải quyết được bước này. Cụ thể hơn, một số kỹ thuật cho bài toán này có thể kể đến như:<p></p>
<ol>
<li><strong>Kỹ thuật xác định dựa vào các kiến thức con người (Knowledge-based)</strong>: Kỹ thuật này dựa vào các hiểu biết của con người về khuôn mặt để xác định được một khuôn mặt trong ảnh (Ví dụ như việc một khuôn mặt sẽ phải có mắt, mũi, miệng và khoảng cách giữa chúng thường sẽ phải thoả mãn các ràng buộc nào đó,..). Điểm khó của kỹ thuật này nằm ở việc chúng ta sẽ phải xây dựng nên 1 bộ quy tắc. Nếu bộ quy tắc quá chung chung hay quá chặt chẽ thì đều không được vì nó sẽ dẫn tới việc nhận dạng nhầm hoặc không nhận dạng được.</li>
<li><strong>Kỹ thuật xác định dựa vào đặc tính khuôn mặt (Feature-based)</strong>: Kỹ thuật này tạo ra một mô hình, sau đó chúng ta sẽ huấn luyện mô hình đó như một mô hình để phân loại (classifier) nhằm xác định trong các khung hình cắt ra từ 1 ảnh ban đầu, đâu là các vùng của một khuôn mặt. Điểm yếu lớn nhất của kỹ thuật này là về mặt thời gian. Có vấn đề này là do chúng ta sẽ phải lấy ra rất nhiều vùng trong 1 bức ảnh nhằm đưa qua classifier.</li>
<li><strong>Kỹ thuật xác định dựa vào mẫu cho trước (Template-Matching)</strong>: Kỹ thuật này xác định được vị trí của một khuôn mặt trong bức ảnh dựa vào việc so sánh giữa các bức ảnh khuôn mặt chúng ta cho trước (Feature template) và các khung hình được cắt ra. Template-Matching rất dễ dàng để sử dụng tuy nhiên cũng gặp phải vấn đề về thời gian tương tự như kỹ thuật Feature-base ở trên.</li>
<li><strong>Kỹ thuật xác định dựa vào hình dáng (Appearance-Base)</strong>: Đây là kỹ thuật mà Dlib sẽ sử dụng, phương pháp sử dụng các phương pháp hình thái học kết hợp với phân tích từ mô hình machine-leanring để xác định trực tiếp về vị trí của các vùng có khuôn mặt trong ảnh. Chúng ta sẽ nói kỹ hơn nữa về kỹ thuật này ở phần sau.</li>
</ol>
<p>Tin vui cho các bạn là chúng ta sẽ không cần phải hiểu tất cả, thậm chí cũng không cần nắm quá rõ về một kỹ thuật nào trong số các kỹ thuật trên mà vẫn có thể thực hiện được dễ dàng bước này.</p>
<p></p><div class="pil-wrapper"><canvas class="pil-placeholder" width="516" height="389"></canvas><div class="pil-tiny-wrapper"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/9cab529c-4286-49f5-a962-bfacaf885667.jpg" class="pil-tiny-img" width="516" height="389"></div><div class="pil-original-wrapper"><img data-pil-src="https://images.viblo.asia/9cab529c-4286-49f5-a962-bfacaf885667.jpg" class="pil-original-img article-img medium-zoom-image" width="516" height="389" data-pil-srcset="https://images.viblo.asia/retina/9cab529c-4286-49f5-a962-bfacaf885667.jpg 2x" data-zoom-src="https://images.viblo.asia/full/9cab529c-4286-49f5-a962-bfacaf885667.jpg"></div></div><p></p>
<p>Đúng như tiêu đề của mình có ghi, mọi việc khó nhất của bước này, chúng ta đều sẽ "nhờ" Dlib giải quyết! <strong>Dlib là một chương trình của thư viện OpenCV, hỗ trợ người dùng trong việc xác định khuôn mặt</strong>.
Thuật toán mà Dlib sử dụng đó là HOG (Histogram of Oriented Gradients) và SVM (Support Vector Machine), đây chính là lý do tại sao Dlib có thời gian chạy rất nhỏ và có thể sử dụng trong các hệ thống thời gian thực. Tuy nhiên gần đây, Dlib cũng đã cung cấp thêm các hàm xác định khuôn mặt dựa trên mạng CNN nên tiếp theo chúng ta sẽ cùng thử cả 2 phương pháp này nhé. Tất cả sẽ có trong đoạn code dưới đây.</p>
<pre class=" language-python" data-filename="" tabindex="0"><code class=" language-python"><span class="token keyword">import</span> time
<span class="token keyword">import</span> dlib
<span class="token keyword">import</span> cv2

<span class="token comment"># Đọc ảnh đầu vào</span>
image <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'/Users/phamhoanganh/Desktop/2.jpg'</span><span class="token punctuation">)</span>

<span class="token comment"># Khai báo việc sử dụng các hàm của dlib</span>
hog_face_detector <span class="token operator">=</span> dlib<span class="token punctuation">.</span>get_frontal_face_detector<span class="token punctuation">(</span><span class="token punctuation">)</span>
cnn_face_detector <span class="token operator">=</span> dlib<span class="token punctuation">.</span>cnn_face_detection_model_v1<span class="token punctuation">(</span><span class="token string">'/Users/phamhoanganh/Desktop/mmod_human_face_detector.dat'</span><span class="token punctuation">)</span>

<span class="token comment"># Thực hiện xác định bằng HOG và SVM</span>
start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
faces_hog <span class="token operator">=</span> hog_face_detector<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Hog + SVM Execution time: "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>end<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Vẽ một đường bao màu xanh lá xung quanh các khuôn mặt được xác định ra bởi HOG + SVM</span>
<span class="token keyword">for</span> face <span class="token keyword">in</span> faces_hog<span class="token punctuation">:</span>
  x <span class="token operator">=</span> face<span class="token punctuation">.</span>left<span class="token punctuation">(</span><span class="token punctuation">)</span>
  y <span class="token operator">=</span> face<span class="token punctuation">.</span>top<span class="token punctuation">(</span><span class="token punctuation">)</span>
  w <span class="token operator">=</span> face<span class="token punctuation">.</span>right<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> x
  h <span class="token operator">=</span> face<span class="token punctuation">.</span>bottom<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> y

  cv2<span class="token punctuation">.</span>rectangle<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token operator">+</span>w<span class="token punctuation">,</span>y<span class="token operator">+</span>h<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># Thực hiện xác định bằng CNN</span>
start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
faces_cnn <span class="token operator">=</span> cnn_face_detector<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"CNN Execution time: "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>end<span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Vẽ một đường bao đỏ xung quanh các khuôn mặt được xác định bởi CNN</span>
<span class="token keyword">for</span> face <span class="token keyword">in</span> faces_cnn<span class="token punctuation">:</span>
  x <span class="token operator">=</span> face<span class="token punctuation">.</span>rect<span class="token punctuation">.</span>left<span class="token punctuation">(</span><span class="token punctuation">)</span>
  y <span class="token operator">=</span> face<span class="token punctuation">.</span>rect<span class="token punctuation">.</span>top<span class="token punctuation">(</span><span class="token punctuation">)</span>
  w <span class="token operator">=</span> face<span class="token punctuation">.</span>rect<span class="token punctuation">.</span>right<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> x
  h <span class="token operator">=</span> face<span class="token punctuation">.</span>rect<span class="token punctuation">.</span>bottom<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> y

  cv2<span class="token punctuation">.</span>rectangle<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token operator">+</span>w<span class="token punctuation">,</span>y<span class="token operator">+</span>h<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

cv2<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span><span class="token string">"image"</span><span class="token punctuation">,</span> image<span class="token punctuation">)</span>
cv2<span class="token punctuation">.</span>waitKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre>
<p>Đi qua một chút về đoạn code trên. Đầu tiên, hãy chắc chắn rằng các bạn đã cài đặt Dlib và thực hiện import.</p>
<pre class=" language-none" data-filename="" tabindex="0"><code class=" language-none">pip install dlib
</code></pre>
<p>Chi tiết hơn về cách cài đặt, các bạn hãy làm theo bài viết này</p>
<blockquote>
<p><a href="https://www.learnopencv.com/install-dlib-on-ubuntu/" target="_blank">https://www.learnopencv.com/install-dlib-on-ubuntu/</a></p>
</blockquote>
<br>
<p>Tiếp theo, mình đọc vào một ảnh bất kỳ, sau đó gán và khai báo các hàm xác định khuôn mặt của Dlib.</p>
<ul>
<li>dlib.get_frontal_face_detector: hàm sử dụng HOG + SVM để xác định khuôn mặt</li>
<li>dlib.cnn_face_detection_model_v1: hàm sử dụng CNN để xác định khuôn mặt, tuy nhiên để sử dụng được hàm này ngay mà không cần huấn luyện lại, chúng ta cần phải load weights của mạng CNN đã được train trước. Các bạn có thể tải xuống weights ở đây và thực hiện khai báo như mình ở trên nhé.</li>
</ul>
<blockquote>
<p><a href="http://arunponnusamy.com/files/mmod_human_face_detector.dat" target="_blank">http://arunponnusamy.com/files/mmod_human_face_detector.dat</a></p>
</blockquote>
<br>
<p>Đây là bức ảnh mà mình sẽ sử dụng để thử
</p><div class="pil-wrapper"><canvas class="pil-placeholder" width="2048" height="1365"></canvas><div class="pil-tiny-wrapper"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/4cefa08f-c6b1-4b37-abff-69205b73a144.jpg" class="pil-tiny-img" width="2048" height="1365"></div><div class="pil-original-wrapper"><img data-pil-src="https://images.viblo.asia/4cefa08f-c6b1-4b37-abff-69205b73a144.jpg" class="pil-original-img article-img medium-zoom-image" width="2048" height="1365" data-pil-srcset="https://images.viblo.asia/retina/4cefa08f-c6b1-4b37-abff-69205b73a144.jpg 2x" data-zoom-src="https://images.viblo.asia/full/4cefa08f-c6b1-4b37-abff-69205b73a144.jpg"></div></div><p></p>
<p>Tiếp đến, chúng ta thực hiện việc gọi hàm xác định khuôn mặt. Ở đây, để so sánh 2 phương pháp, trước và sau mỗi khi thực hiện hàm xác định của mỗi phương pháp, mình đầu ghi lại thời gian để tiện cho việc so sánh sau này.</p>
<pre class=" language-python" data-filename="" tabindex="0"><code class=" language-python">faces_hog <span class="token operator">=</span> hog_face_detector<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
faces_cnn <span class="token operator">=</span> cnn_face_detector<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre>
<p>Tham số cần truyền vào cả 2 hàm đều là ảnh đầu vào và số lượng của cửa sổ tìm kiếm. Nếu số này càng lớn, đồng nghĩa với việc sẽ có thêm các cửa sổ tìm kiếm (kích thước cửa sổ mới sẽ nhỏ dần). Điều này giúp ta nhận ra được các khuôn mặt ở xa (bị nhỏ) ở trong ảnh tuy nhiên đánh đổi bằng việc thời gian chạy sẽ tăng theo cấp số mũ. Ở đây mình chỉ để 1 cửa sổ.</p>
<p>Cả 2 hàm đều trả về cho chúng ta 1 list các toạ độ của các khuôn mặt có trong ảnh, và từ đó mình sẽ thực hiện vẽ lên ảnh các đường bao chữ nhật.</p>
<p><strong>LƯU Ý</strong>: Để phân biệt thì đối với các khuôn mặt được xác định nhờ HOG+SVM, mình sẽ vẽ đường bao màu xanh, còn các vùng được xác định nhờ CNN, mình sẽ vẽ đường bao màu đỏ! Hãy cùng xem kết quả.
</p><div class="pil-wrapper"><canvas class="pil-placeholder" width="800" height="533"></canvas><div class="pil-tiny-wrapper"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/924f1337-a96a-4c42-a24b-9cf22273fbdf.jpg" class="pil-tiny-img" width="800" height="533"></div><div class="pil-original-wrapper"><img data-pil-src="https://images.viblo.asia/924f1337-a96a-4c42-a24b-9cf22273fbdf.jpg" class="pil-original-img article-img medium-zoom-image" width="800" height="533" data-pil-srcset="https://images.viblo.asia/retina/924f1337-a96a-4c42-a24b-9cf22273fbdf.jpg 2x" data-zoom-src="https://images.viblo.asia/full/924f1337-a96a-4c42-a24b-9cf22273fbdf.jpg"></div></div>
Dễ thấy rằng CNN cho ta kết quả gần như tuyệt đối, còn đối với phương pháp HOG kết hợp SVM, chúng ta hãy để ý những trường hợp phương pháp này không xác định được... Chắc các bạn cũng đều nhận ra, HOG+SVM bị bỏ qua các khuôn mặt quay nghiêng góc hoặc bị che một phần. Điều này đúng với tên hàm mà Dlib cung cấp cho chúng ta <strong>get_frontal_face_detector</strong>!!<p></p>
<p>Tuy nhiên trước khi buông lời phán xét, hãy xem thêm thông số về thời gian mà mình cho in ra</p>
<blockquote>
<p>Hog + SVM Execution time: 0.1367199420928955<br>
CNN Execution time: 4.2889978885650635</p>
</blockquote>
<p>Với một bức ảnh khoảng 800x600 pixel như thế này, phương pháp sử dụng HOG kết hợp SVM mất khoảng 0.13 giây để xác định được toàn bộ khuôn mặt, còn phương pháp CNN lại phải mất tới 4.29 giây (gấp khoảng 40 lần). Sự chênh lệch này sẽ lớn hơn rất nhiều nếu chúng ta thử trên một bức ảnh chất lượng cao hơn. Tuy nhiên do hiện nay mình đang sử dụng MBP2017 là 1 loại máy không hỗ trợ về tính toán, GPU quá mạnh nên phương pháp CNN tỏ ra kém hiệu quả. Vậy nên với "cơ sở vật chất" của mình thì mình sẽ chọn sẽ dụng phương pháp HOG + SVM để đảm bảo được hệ thống của mình sẽ hoạt động được với <strong>thời gian thực</strong> nhé!!</p>
<br>
<p>Đến đây, chúng ta đã xử lý xong bước đầu tiên theo một cách ... rất dễ dàng và tiện lợi nhờ sự hỗ trợ của DLIB. Hệ thống của chúng ta đã có thể xác định được các vị trị khuôn mặt ở trong ảnh! Ngoài ra, Dlib còn hỗ trợ chúng ta lấy ra các điểm quan trọng trên khuôn mặt (Landmark), tuy nhiên mình sẽ không đề cập tới trong bài viết này vì hệ thống chúng ta đang xây dựng hoàn toàn không sử dụng chúng.</p>
<h2 id="_bieu-dien-cac-khuon-mat-duoi-dang-vector-4">Biểu diễn các khuôn mặt dưới dạng vector</h2>
<p>Nói đến việc nhận dạng, xác định khuôn mặt này là "của ai", chúng ta sẽ cần tính độ GIỐNG/ KHÁC nhau giữa các khuôn mặt chúng ta lấy được. Và nói về độ GIỐNG/ KHÁC nhau, để đơn giản, chúng ta sẽ quy về bài toán <strong>Tính khoảng cách giữa các vector</strong>. Dù là trong xử lý âm thanh hay xử lý ảnh hay xử lý ngôn ngữ tự nhiên, việc chuyển về vector để tính khoảng cách đều là một lựa chọn rất tốt. Và trong bài viết này, mình sẽ biến các khung hình khuôn mặt về các vector có 128 chiều (số chiều này là do sau nhiều lần mình thử và chọn ra, các bạn có thể thử và lựa chọn số khác).</p>
<p>Về lý thuyết thì là như vậy, nhưng vấn đề quan trọng nhất ở đấy chính là</p>
<blockquote>
<p><strong>CẦN MỘT MÔ HÌNH CHUYỂN TỪ KHUNG HÌNH KHUÔN MẶT SANG VECTOR, SAO CHO ẢNH 2 KHUÔN MẶT GẦN NHAU THÌ 2 VECTOR TƯƠNG ỨNG CŨNG PHẢI CÓ KHOẢNG CÁCH GẦN NHAU. ẢNH 2 KHUÔN MẶT KHÁC NHAU THÌ 2 VECTOR TƯƠNG ỨNG CŨNG PHẢI XA NHAU HƠN.</strong></p>
</blockquote>
<p>Và để giải quyết vấn đề này, mình sẽ giới thiệu cho các bạn mô hình học sâu ConvNet sử dụng hàm loss Triplet.</p>
<h3 id="_triplet-la-gi-5">Triplet là gì?</h3>
<p>Tiếng việt của Triplet có thể tạm được dịch ra là "bộ ba". Với rất nhiều các bài toán khác trước đây của các mô hình học sâu, thông thường chúng ta sẽ cho lần lượt từng ảnh một vào để mô hình học, tuy nhiên với bài toán lần này, chúng ta sẽ phải sử dụng từng "bộ ba".</p>
<p>Bộ ba của chúng ta bao gồm: 1 ảnh mặt của 1 người bất kỳ (query), 1 ảnh mặt khác của người đó (positive), 1 ảnh mặt của người khác (negative). Với việc huấn luyện mô hình như thế, chúng ta sẽ có thêm thông tin về mối quan hệ giữa các ảnh, điều này giúp mô hình chúng ta phù hợp hơn nhiều với bài toán.</p>
<h3 id="_convnet-6">ConvNet</h3>
<p></p><div class="pil-wrapper"><canvas class="pil-placeholder" width="883" height="453"></canvas><div class="pil-tiny-wrapper"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/7f274c8c-a2ba-400f-bf2a-180c7c3b4804.png" class="pil-tiny-img" width="883" height="453"></div><div class="pil-original-wrapper"><img data-pil-src="https://images.viblo.asia/7f274c8c-a2ba-400f-bf2a-180c7c3b4804.png" class="pil-original-img article-img medium-zoom-image" width="883" height="453" data-pil-srcset="https://images.viblo.asia/retina/7f274c8c-a2ba-400f-bf2a-180c7c3b4804.png 2x" data-zoom-src="https://images.viblo.asia/full/7f274c8c-a2ba-400f-bf2a-180c7c3b4804.png"></div></div>
Đây là một mạng học sâu với cấu trúc 3 nhánh. Với 1 ảnh đưa vào, chúng ta sẽ thu được 1 vector cuối cùng đầu ra (Trong ảnh là 4096 chiều, còn mình sẽ đưa về 128 chiều). Điểm khác ở đây là ảnh sẽ được phân tích theo 3 mô hình khác nhau, mô hình đã được chứng minh hiệu quả trong nhiều bài toán/ cuộc thi xử lý ảnh khác. Vậy nên chúng ta sẽ sử dụng ConvNet trên trong bài toán lần này.<p></p>
<h3 id="_triplet-loss-7">Triplet loss</h3>
<p>Một lần nữa</p>
<blockquote>
<p><strong>CẦN MỘT MÔ HÌNH CHUYỂN TỪ KHUNG HÌNH KHUÔN MẶT SANG VECTOR, SAO CHO ẢNH 2 KHUÔN MẶT GẦN NHAU THÌ 2 VECTOR TƯƠNG ỨNG CŨNG PHẢI CÓ KHOẢNG CÁCH GẦN NHAU. ẢNH 2 KHUÔN MẶT KHÁC NHAU THÌ 2 VECTOR TƯƠNG ỨNG CŨNG PHẢI XA NHAU HƠN.</strong></p>
</blockquote>
<p>Vậy làm sao mô hình của chúng ta hiểu được điều này khi huấn luyện để có thể giúp chúng ta tạo ra các vector như ý? Đây chính là lúc việc sử dụng "bộ ba" trở nên hiệu quả. Và hàm loss của mô hình chúng ta sẽ có dạng như sau
</p><div class="pil-wrapper"><canvas class="pil-placeholder" width="928" height="78"></canvas><div class="pil-tiny-wrapper"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/3fbe06b0-8023-4ad0-96ae-0781c86193c1.png" class="pil-tiny-img" width="928" height="78"></div><div class="pil-original-wrapper"><img data-pil-src="https://images.viblo.asia/3fbe06b0-8023-4ad0-96ae-0781c86193c1.png" class="pil-original-img article-img medium-zoom-image" width="928" height="78" data-pil-srcset="https://images.viblo.asia/retina/3fbe06b0-8023-4ad0-96ae-0781c86193c1.png 2x" data-zoom-src="https://images.viblo.asia/full/3fbe06b0-8023-4ad0-96ae-0781c86193c1.png"></div></div><p></p>
<p>Với <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault">p</span><span class="mclose">)</span></span></span></span> là vector biểu diễn <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault">p</span></span></span></span>.  <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">D</span></span></span></span> là khoảng cách giữa 2 vector. Hàm loss của chúng ta sẽ là [<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mi>l</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">-l]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">−</span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mclose">]</span></span></span></span>. Nhìn qua một chút, chúng ta đang huấn luỵên để cho hàm trên  <strong>CÀNG LỚN CÀNG TỐT (max)</strong>. Điều này có nghĩa là mô hình chúng ta sẽ cố gắng học sao cho càng ngày, nó càng giảm khoảng cách giữa 2 vector <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(p_i)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> (Query Image) và <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msubsup><mi>p</mi><mi>i</mi><mo>+</mo></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">f(p_i^+)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.088326em;vertical-align:-0.276864em;"></span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.811462em;"><span style="top:-2.4231360000000004em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span style="top:-3.1031310000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.276864em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> (Positive Image), và tăng khoảng cách giữa Query Image và Negative Image! Đây là điều chúng ta đang muốn mô hình học được</p>
<h3 id="_chuan-bi-du-lieu-huan-luyen-mo-hinh-8">Chuẩn bị dữ liệu huấn luyện mô hình</h3>
<p>Đối với tuỳ từng tổ chức, mục đích sử dụng, chúng ta nên có 1 tập dữ liệu đặc thù, nhưng ở đây mình đang mô phỏng lại một hệ thống, vậy nên mình sẽ sử dụng 1 bộ data lớn một chút để thử nghiệm. Và ở đây mình chọn thử nghiệm hệ thống trên tập Labeled Face in Wild (LFW). Dataset này bao gồm hơn 13000 ảnh mặt người (được gán nhãn) thu thập trên mạng internet. Các bạn có thể tìm thấy bộ dữ liệu này ở đây</p>
<br>
<p>LFW Dataset: <a href="http://vis-www.cs.umass.edu/lfw/" target="_blank">http://vis-www.cs.umass.edu/lfw/</a></p>
<h3 id="_huan-luyen-mo-hinh-9">Huấn luyện mô hình</h3>
<pre class=" language-python" data-filename="" tabindex="0"><code class=" language-python"><span class="token keyword">def</span> <span class="token function">convnet_model_</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    vgg_model <span class="token operator">=</span> applications<span class="token punctuation">.</span>VGG16<span class="token punctuation">(</span>weights<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> include_top<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">221</span><span class="token punctuation">,</span> <span class="token number">221</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> vgg_model<span class="token punctuation">.</span>output
    x <span class="token operator">=</span> GlobalAveragePooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.6</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> x_<span class="token punctuation">:</span> K<span class="token punctuation">.</span>l2_normalize<span class="token punctuation">(</span>x<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment">#     x = Lambda(K.l2_normalize)(x)</span>
    convnet_model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span>vgg_model<span class="token punctuation">.</span><span class="token builtin">input</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span>x<span class="token punctuation">)</span>
    <span class="token keyword">return</span> convnet_model

<span class="token keyword">def</span> <span class="token function">deep_rank_model</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    convnet_model <span class="token operator">=</span> convnet_model_<span class="token punctuation">(</span><span class="token punctuation">)</span>

    first_input <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">221</span><span class="token punctuation">,</span> <span class="token number">221</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    first_conv <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>first_input<span class="token punctuation">)</span>
    first_max <span class="token operator">=</span> MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>first_conv<span class="token punctuation">)</span>
    first_max <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>first_max<span class="token punctuation">)</span>
    first_max <span class="token operator">=</span> Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> K<span class="token punctuation">.</span>l2_normalize<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>first_max<span class="token punctuation">)</span>

    second_input <span class="token operator">=</span> Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">221</span><span class="token punctuation">,</span> <span class="token number">221</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    second_conv <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>second_input<span class="token punctuation">)</span>
    second_max <span class="token operator">=</span> MaxPool2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>second_conv<span class="token punctuation">)</span>
    second_max <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>second_max<span class="token punctuation">)</span>
    second_max <span class="token operator">=</span> Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> K<span class="token punctuation">.</span>l2_normalize<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>second_max<span class="token punctuation">)</span>
                       
    merge_one <span class="token operator">=</span> concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>first_max<span class="token punctuation">,</span> second_max<span class="token punctuation">]</span><span class="token punctuation">)</span>
    merge_two <span class="token operator">=</span> concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>merge_one<span class="token punctuation">,</span> convnet_model<span class="token punctuation">.</span>output<span class="token punctuation">]</span><span class="token punctuation">)</span>
    emb <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">(</span>merge_two<span class="token punctuation">)</span>
    emb <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
    l2_norm_final <span class="token operator">=</span> Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> K<span class="token punctuation">.</span>l2_normalize<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">(</span>emb<span class="token punctuation">)</span>
                        
    final_model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span><span class="token punctuation">[</span>first_input<span class="token punctuation">,</span> second_input<span class="token punctuation">,</span> convnet_model<span class="token punctuation">.</span><span class="token builtin">input</span><span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span>l2_norm_final<span class="token punctuation">)</span>

    <span class="token keyword">return</span> final_model
</code></pre>
<pre class=" language-python" data-filename="" tabindex="0"><code class=" language-python">deep_rank_model <span class="token operator">=</span> deep_rank_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>Mình xây dựng theo đúng mô hình ConvNet đã nói ở trên, 1 ảnh sẽ được đưa vào 3 đường khác nhau, trước khi nối lại để tạo thành 1 vector 128 chiều. Vector này sẽ đại diện cho bức ảnh, và khi mô hình được huấn luyện tốt, 128 thuộc tính này có thể coi như là 128 thuộc tính <strong>đặc trưng</strong> của khuôn mặt đó. Cũng vì đó, bước huấn luyện mô hình từ khuôn mặt sang vector còn gọi là bước <strong>TRÍCH CHỌN ĐẶC TRƯNG</strong>.</p>
<br>
<p>Giờ chúng ta sẽ code hàm triplet loss đúng theo công thức</p>
<pre class=" language-python" data-filename="" tabindex="0"><code class=" language-python">batch_size <span class="token operator">=</span> <span class="token number">24</span>

_EPSILON <span class="token operator">=</span> K<span class="token punctuation">.</span>epsilon<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">_loss_tensor</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_pred <span class="token operator">=</span> K<span class="token punctuation">.</span>clip<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> _EPSILON<span class="token punctuation">,</span> <span class="token number">1.0</span> <span class="token operator">-</span> _EPSILON<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">.</span>
    g <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            q_embedding <span class="token operator">=</span> y_pred<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
            p_embedding <span class="token operator">=</span> y_pred<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>
            n_embedding <span class="token operator">=</span> y_pred<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">]</span>
            D_q_p <span class="token operator">=</span> K<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>K<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>q_embedding <span class="token operator">-</span> p_embedding<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            D_q_n <span class="token operator">=</span> K<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>K<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">(</span>q_embedding <span class="token operator">-</span> n_embedding<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss <span class="token operator">+</span> g <span class="token operator">+</span> D_q_p <span class="token operator">-</span> D_q_n
        <span class="token keyword">except</span><span class="token punctuation">:</span>
            <span class="token keyword">continue</span>
    loss <span class="token operator">=</span> loss<span class="token operator">/</span>batch_size<span class="token operator">*</span><span class="token number">3</span>
    <span class="token keyword">return</span> K<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python" data-filename="" tabindex="0"><code class=" language-python">deep_rank_model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span>_loss_tensor<span class="token punctuation">,</span> optimizer<span class="token operator">=</span>SGD<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> nesterov<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<p>Một điểm khác mà mình đã nói từ đầu trong việc huấn luyện mô hình này đó là việc chúng ta sẽ đưa ảnh theo BỘ BA. Và từ đó hàm loss cũng sẽ tính theo các BỘ BA, không phải tính riêng từng đầu ra như các mô hình khác.</p>
<br>
<p>Đây là cách mình chọn BỘ BA, ảnh đầu sẽ được coi là ảnh query, ảnh tiếp theo sẽ là positive (ảnh cùng class) và cuối cùng là ảnh negative (ảnh khác class)</p>
<pre class=" language-python" data-filename="" tabindex="0"><code class=" language-python"><span class="token keyword">def</span> <span class="token function">image_batch_generator</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    labels <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
        batch_paths <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>a <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">,</span> size <span class="token operator">=</span> batch_size<span class="token operator">//</span><span class="token number">3</span><span class="token punctuation">)</span>
        input_1 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        
        <span class="token keyword">for</span> i <span class="token keyword">in</span> batch_paths<span class="token punctuation">:</span>
            pos <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>labels <span class="token operator">==</span> labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            neg <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>labels <span class="token operator">!=</span> labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            
            j <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>pos<span class="token punctuation">)</span>
            <span class="token keyword">while</span> j <span class="token operator">==</span> i<span class="token punctuation">:</span>
                j <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>pos<span class="token punctuation">)</span>
             
            k <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>neg<span class="token punctuation">)</span>
            <span class="token keyword">while</span> k <span class="token operator">==</span> i<span class="token punctuation">:</span>
                k <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>neg<span class="token punctuation">)</span>
            
            input_1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>images<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
            input_1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>images<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
            input_1<span class="token punctuation">.</span>append<span class="token punctuation">(</span>images<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span>

        input_1 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>input_1<span class="token punctuation">)</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token punctuation">[</span>input_1<span class="token punctuation">,</span> input_1<span class="token punctuation">,</span> input_1<span class="token punctuation">]</span>
        <span class="token keyword">yield</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
<pre class=" language-python" data-filename="" tabindex="0"><code class=" language-python">deep_rank_model<span class="token punctuation">.</span>fit_generator<span class="token punctuation">(</span>generator<span class="token operator">=</span>image_batch_generator<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                   steps_per_epoch<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token operator">//</span>batch_size<span class="token punctuation">,</span>
                   epochs<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span>
                   verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                   callbacks<span class="token operator">=</span>callbacks_list<span class="token punctuation">)</span>
</code></pre>
<h3 id="_mo-phong-ket-qua-data-visualize-10">Mô phỏng kết quả (Data Visualize)</h3>
<p>Sau khi đã training xong, chúng ta muốn theo dõi kết quả 1 cách trực quan hơn. Liệu mô hình chúng ta có làm tốt được nhiệm vụ trích chọn đặc trưng, và khiến cho những khuôn mặt giống nhau thì về gần nhau, còn ngược lại thì xa nhau không? Để có thể <strong>NHÌN RÕ ĐIỀU NÀY 1 CÁCH TRỰC QUAN</strong>, chúng ta sẽ cần sử dụng thuật toán t-SNE. Thuật toán sẽ giúp chúng ta đưa từ không gian vector 128 chiều về không gian 3 chiều, giúp mắt ta quan sát dễ dàng nhất. Cụ thể về thuật toán và cách mô phỏng mình sẽ không đề cập ở đây, các bạn muốn tìm hiểu thêm, có thể đọc bài viết rất "có tâm" này của tác giả Phan Hoàng nhé:</p>
<p><br><a href="https://viblo.asia/p/data-visualization-voi-thuat-toan-t-sne-su-dung-tensorflow-projector-924lJAAzZPM" target="_blank">https://viblo.asia/p/data-visualization-voi-thuat-toan-t-sne-su-dung-tensorflow-projector-924lJAAzZPM</a></p>
<br>
<p>Đây là kết quả Visualize của mình:
<br></p>
<p></p><div class="pil-wrapper"><canvas class="pil-placeholder" width="600" height="371"></canvas><div class="pil-tiny-wrapper"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/09060172-06a8-472d-ba9b-507cd35bb1b9.gif" class="pil-tiny-img" width="600" height="371"></div><div class="pil-original-wrapper"><img data-pil-src="https://images.viblo.asia/09060172-06a8-472d-ba9b-507cd35bb1b9.gif" class="pil-original-img article-img medium-zoom-image" width="600" height="371" data-pil-srcset="https://images.viblo.asia/retina/09060172-06a8-472d-ba9b-507cd35bb1b9.gif 2x" data-zoom-src="https://images.viblo.asia/full/09060172-06a8-472d-ba9b-507cd35bb1b9.gif"></div></div><p></p>
<p>Hoặc các bạn có thể xem trực tiếp tại: <a href="https://hoanganhpham1006.github.io/face-detector-Visualize/" target="_blank">https://hoanganhpham1006.github.io/face-detector-Visualize/</a></p>
<p>Các bạn hãy chọn t-SNE rồi đợi cho nó training khoảng 300-400 iter rồi dừng nhé. Việc training ở đây là training để đưa từ không gian 128 chiều về không gian 3 chiều, hoàn toàn không liên quan tới việc huấn luyện mình viết trong bài này</p>
<p>Do mình training cũng chưa đủ lâu, nên các ảnh cũng chưa thực sự phân cụm 1 cách rõ ràng, tuy nhiên những ảnh cùng 1 người hoặc 2 người giống nhau đều nằm khá gần nhau trong không gian này!</p>
<br>
<p>Vậy là chúng ta đã có một mô hình để chuyển từ ảnh khuôn mặt sang vector đúng theo ý đồ của chúng ta. Giờ chúng ta sẽ sang bước cuối cùng nhé!</p>
<h2 id="_xac-minh-danh-tinh-khuon-mat-11">Xác minh danh tính khuôn mặt</h2>
<p>Cách đơn giản và không kém hiệu quả chính là tính khoảng cách Euclit của vector đặc trưng khuôn mặt đang cần nhận dạng với các vector đặc trưng khác, và lấy vector <strong>GẦN NÓ NHẤT</strong> làm kết quả xác minh</p>
<pre class=" language-python" data-filename="" tabindex="0"><code class=" language-python"><span class="token comment"># Với mỗi khung hình mặt phát hiện ra</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
frame <span class="token operator">=</span> image<span class="token punctuation">[</span>y<span class="token punctuation">:</span>y<span class="token operator">+</span>h<span class="token punctuation">,</span> x<span class="token punctuation">:</span>x<span class="token operator">+</span>w<span class="token punctuation">]</span>
frame <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>frame<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">221</span><span class="token punctuation">,</span> <span class="token number">221</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
frame <span class="token operator">=</span> frame <span class="token operator">/</span><span class="token number">255</span><span class="token punctuation">.</span>
frame <span class="token operator">=</span> np<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>frame<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
emb128 <span class="token operator">=</span> deep_rank_model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>frame<span class="token punctuation">,</span> frame<span class="token punctuation">,</span> frame<span class="token punctuation">]</span><span class="token punctuation">)</span>
minimum <span class="token operator">=</span> <span class="token number">99999</span>
person <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>
<span class="token keyword">for</span> k<span class="token punctuation">,</span> e <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>embs128<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#Euler distance</span>
    dist <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>emb128<span class="token operator">-</span>e<span class="token punctuation">)</span>
    <span class="token keyword">if</span> dist <span class="token operator">&lt;</span> minimum<span class="token punctuation">:</span>
        minimum <span class="token operator">=</span> dist
        person <span class="token operator">=</span> k
cv2<span class="token punctuation">.</span>putText<span class="token punctuation">(</span>image<span class="token punctuation">,</span> names<span class="token punctuation">[</span>person<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> <span class="token number">10</span><span class="token punctuation">,</span> y <span class="token operator">-</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    cv2<span class="token punctuation">.</span>FONT_HERSHEY_SIMPLEX<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
</code></pre>
<p></p><div class="pil-wrapper"><canvas class="pil-placeholder" width="800" height="800"></canvas><div class="pil-tiny-wrapper"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/65f8c265-836b-4239-a09c-86dd69b15d23.jpg" class="pil-tiny-img" width="800" height="800"></div><div class="pil-original-wrapper"><img data-pil-src="https://images.viblo.asia/65f8c265-836b-4239-a09c-86dd69b15d23.jpg" class="pil-original-img article-img medium-zoom-image" width="800" height="800" data-pil-srcset="https://images.viblo.asia/retina/65f8c265-836b-4239-a09c-86dd69b15d23.jpg 2x" data-zoom-src="https://images.viblo.asia/full/65f8c265-836b-4239-a09c-86dd69b15d23.jpg"></div></div><p></p>
<p>Ngoài ra để có thể tăng tính chính xác hơn nữa, các bạn hãy thêm 1 "ngưỡng khoảng cách tối đa". Nếu vector chúng ta cần xác định nằm quá xa so với các vector còn lại, thì khả năng cao chúng <strong>không phải của người nào trong số dữ liệu chúng ta đang có</strong></p>
<h1 id="_ket-luan-12">Kết luận</h1>
<p>Như vậy mình đã xây dựng xong hệ thống nhận dạng khuôn mặt của mình. Hy vọng các bạn sẽ có thể thực hiện theo và thành công! Mọi thắc mắc hãy để lại dưới comment nhé, mình rất sẵn lòng để giải đáp!</p>
<p>Link source code: <a href="https://github.com/hoanganhpham1006/face-detector" target="_blank">https://github.com/hoanganhpham1006/face-detector</a></p>
<p>Cảm ơn các bạn đã quan tâm theo dõi</p>
</div> <!----> <div class="tags" data-v-190ce5c0=""> <a href="https://viblo.asia/tags/machine-learning" class="el-tag tag el-tag--info el-tag--medium" data-v-1ebc36b8="" data-v-190ce5c0="">
        Machine Learning
    </a><a href="https://viblo.asia/tags/deep-learning" class="el-tag tag el-tag--info el-tag--medium" data-v-1ebc36b8="" data-v-190ce5c0="">
        Deep Learning
    </a><a href="https://viblo.asia/tags/open-cv" class="el-tag tag el-tag--info el-tag--medium" data-v-1ebc36b8="" data-v-190ce5c0="">
        Open CV
    </a> </div> <br> <p title="People cannot distribute, remix, adapt, and build upon this workwithout author&#39;s permission (or as permitted by fair use)." class="license-text text-muted">
    All rights reserved
</p> <div class="post-footer d-flex align-items-center justify-content-end mb-2"><div class="social-sharing mr-1 social-sharing--vertical social-sharing--medium" data-v-92417f3e=""><a tooltip-placement="bottom" rel="noopener" class="link link--muted link--muted" data-v-92417f3e="" data-tippy="" data-original-title="Chia sẻ liên kết đến trang này trên Facebook"><i aria-hidden="true" class="fa fa-facebook" data-v-92417f3e=""></i></a> <a tooltip-placement="bottom" rel="noopener" class="link link--muted link--muted" data-v-92417f3e="" data-tippy="" data-original-title="Chia sẻ liên kết đến trang này trên Twitter"><i aria-hidden="true" class="fa fa-twitter" data-v-92417f3e=""></i></a></div> <div class="post__menu"><div class="el-dropdown"><button type="button" class="el-button p-0 el-button--text text-muted el-dropdown-selfdefine" data-tippy="" data-original-title="Hiển thị các hành động" aria-haspopup="list" aria-controls="dropdown-menu-9239" role="button" tabindex="0"><!----><i class="post__menu__more el-icon-more-outline"></i><!----></button> <ul class="el-dropdown-menu el-popper el-dropdown-menu--medium" style="display:none;" id="dropdown-menu-9239"><!----> <li tabindex="-1" class="el-dropdown-menu__item"><!----><i aria-hidden="true" class="fa fa-flag-o pr-0 mr-05"></i>
                Báo cáo
            </li> <!----> <!----> <!----> <!----> <!----> <!----> <!----></ul></div> <!----> <!----> <!----> <!----></div></div></article></div> <div class="post-body__right hidden-md-down"><div class="sidebar-wrapper post-sidebar post-body__sidebar"><div class="dummy"></div> <div class="sticky-sidebar" style="top: 80px; max-height: calc(100vh - 88px); overflow-y: hidden;"><div class="post-index hidden-sm-down"><div class="section-title-line"><h4 class="text-uppercase">
            Mục lục
        </h4> <hr class="filler-line"></div> <ul class="content-outline list-unstyled"><li class="content-outline__item content-outline__item--level-1"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_he-thong-kiem-soat-nhan-dang-khuon-mat-la-gi-0" class="link">Hệ thống kiểm soát nhận dạng khuôn mặt là gì?</a></li><li class="content-outline__item content-outline__item--level-1"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_muc-tieu-1" class="link">Mục tiêu</a></li><li class="content-outline__item content-outline__item--level-1"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_xay-dung-he-thong-nhan-dang-khuon-mat-2" class="link">Xây dựng hệ thống nhận dạng khuôn mặt</a></li><li class="content-outline__item content-outline__item--level-2"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_xac-dinh-khuon-mat-trong-anh-facial-detection---viec-kho-da-co-dlib-lo-3" class="link">Xác định khuôn mặt trong ảnh (Facial detection) - Việc khó đã có Dlib lo</a></li><li class="content-outline__item content-outline__item--level-2"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_bieu-dien-cac-khuon-mat-duoi-dang-vector-4" class="link">Biểu diễn các khuôn mặt dưới dạng vector</a></li><li class="content-outline__item content-outline__item--level-3"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_triplet-la-gi-5" class="link">Triplet là gì?</a></li><li class="content-outline__item content-outline__item--level-3"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_convnet-6" class="link">ConvNet</a></li><li class="content-outline__item content-outline__item--level-3"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_triplet-loss-7" class="link">Triplet loss</a></li><li class="content-outline__item content-outline__item--level-3"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_chuan-bi-du-lieu-huan-luyen-mo-hinh-8" class="link">Chuẩn bị dữ liệu huấn luyện mô hình</a></li><li class="content-outline__item content-outline__item--level-3"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_huan-luyen-mo-hinh-9" class="link">Huấn luyện mô hình</a></li><li class="content-outline__item content-outline__item--level-3"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_mo-phong-ket-qua-data-visualize-10" class="link">Mô phỏng kết quả (Data Visualize)</a></li><li class="content-outline__item content-outline__item--level-2"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_xac-minh-danh-tinh-khuon-mat-11" class="link">Xác minh danh tính khuôn mặt</a></li><li class="content-outline__item content-outline__item--level-1"><a href="https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3#_ket-luan-12" class="link">Kết luận</a></li></ul></div> <!----> <br> <!----></div></div></div></div></div> <div class="post-recommendations"><div class="container py-2"><!----> <div class="post-comments"><h3 class="mb-2"><strong>Bình luận</strong></h3> <div class="text-center text-muted"><i aria-hidden="true" class="fa fa-circle-o-notch fa-spin"></i> <span>Đang tải thêm bình luận...</span></div></div></div></div> <!----> <div data-v-80e5955e="" class="post-bottom-bar fixed-bottom hidden-lg-up"><a data-v-80e5955e="" href="https://viblo.asia/u/hoanganhpham" class="d-flex avatar" name="Phạm Hoàng Anh"><img data-v-5e990434="" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/f4849a25-3687-49cb-ab03-53c9597435f0.jpg" srcset="https://images.viblo.asia/avatar-retina/f4849a25-3687-49cb-ab03-53c9597435f0.jpg 2x" alt="Avatar" class="avatar avatar--md"></a> <div data-v-c87213ec="" data-v-80e5955e="" class="ratings ml-1"><a data-v-80e5955e="" data-v-c87213ec="" class="vote"><i data-v-80e5955e="" data-v-c87213ec="" aria-hidden="true" class="fa fa-arrow-up"></i></a> <div data-v-80e5955e="" data-v-c87213ec="" class="points">
                +29
            </div> <a data-v-80e5955e="" data-v-c87213ec="" class="vote"><i data-v-80e5955e="" data-v-c87213ec="" aria-hidden="true" class="fa fa-arrow-down"></i></a></div> <!----> <!----> <div data-v-92417f3e="" data-v-80e5955e="" class="social-sharing sharings d-flex align-items-center social-sharing--vertical social-sharing--small"><div data-v-80e5955e="" class="subscribe" data-v-92417f3e=""><button data-v-80e5955e="" type="button" class="el-button sharing-item clip p-0 el-button--text"><!----><i class="fa fa-bookmark"></i><!----></button></div> <span data-v-80e5955e="" data-v-92417f3e="" class="text-muted hidden-lg-up">•</span> <span data-v-ff3977b0="" data-v-23e635c8="" data-v-80e5955e="" data-v-92417f3e=""><div role="tooltip" id="el-popover-2116" aria-hidden="true" class="el-popover el-popper" tabindex="0" style="display: none;"><!----><div data-v-ff3977b0="" class="type-control-options"><div data-v-ff3977b0=""><i data-v-ff3977b0="" class="fa fa-font control-icon"></i> <span data-v-ff3977b0="">Cỡ chữ</span></div> <div data-v-ff3977b0=""><button data-v-ff3977b0="" type="button" class="el-button button-modify el-button--default el-button--mini is-circle"><!----><!----><span><i data-v-ff3977b0="" class="fa fa-minus"></i></span></button> <span data-v-ff3977b0="" class="control-info">18px</span> <button data-v-ff3977b0="" type="button" class="el-button button-modify el-button--default el-button--mini is-circle"><!----><!----><span><i data-v-ff3977b0="" class="fa fa-plus"></i></span></button></div> <div data-v-ff3977b0=""><i data-v-ff3977b0="" class="fa fa-text-height control-icon"></i> <span data-v-ff3977b0="">Độ cao hàng</span></div> <div data-v-ff3977b0=""><button data-v-ff3977b0="" type="button" class="el-button button-modify el-button--default el-button--mini is-circle"><!----><!----><span><i data-v-ff3977b0="" class="fa fa-minus"></i></span></button> <span data-v-ff3977b0="" class="control-info">1.75</span> <button data-v-ff3977b0="" type="button" class="el-button button-modify el-button--default el-button--mini is-circle"><!----><!----><span><i data-v-ff3977b0="" class="fa fa-plus"></i></span></button></div></div> <div data-v-ff3977b0="" class="d-flex mode-theme mt-1"><div data-v-ff3977b0="" role="radiogroup" class="el-radio-group"><label data-v-ff3977b0="" role="radio" tabindex="-1" class="el-radio-button"><input type="radio" tabindex="-1" class="el-radio-button__orig-radio" value="false"><span class="el-radio-button__inner">
                Mặc định
            <!----></span></label> <label data-v-ff3977b0="" role="radio" tabindex="-1" class="el-radio-button"><input type="radio" tabindex="-1" class="el-radio-button__orig-radio" value="true"><span class="el-radio-button__inner">
                Toàn màn hình
            <!----></span></label></div></div> <div data-v-ff3977b0="" class="d-flex mode-theme mt-1"><p data-v-ff3977b0="">
            Màu nền
        </p> <p data-v-ff3977b0="" class="color-mode color-white background-button-mode"></p> <p data-v-ff3977b0="" class="color-mode color-dark"></p> <p data-v-ff3977b0="" class="color-mode color-sepia"></p></div> <div data-v-ff3977b0="" class="reset-default mt-1"><button data-v-ff3977b0="" type="button" class="el-button button-reset el-button--default el-button--mini"><!----><!----><span>
            Đặt lại
        </span></button></div> </div><span class="el-popover__reference-wrapper"><button data-v-23e635c8="" type="button" class="el-button is-circle type-control el-button--default el-popover__reference" aria-describedby="el-popover-2116" tabindex="0"><!----><!----><span><i data-v-23e635c8="" class="fa fa-font"></i></span></button></span></span> <span data-v-80e5955e="" data-v-92417f3e="" class="text-muted hidden-lg-up">•</span> <a data-v-80e5955e="" data-v-92417f3e="" class="sharing-item"><i data-v-80e5955e="" data-v-92417f3e="" aria-hidden="true" class="fa fa-facebook"></i></a> <span data-v-80e5955e="" data-v-92417f3e="" class="text-muted">•</span> <a data-v-80e5955e="" data-v-92417f3e="" class="sharing-item"><i data-v-80e5955e="" data-v-92417f3e="" aria-hidden="true" class="fa fa-twitter"></i></a> <span data-v-80e5955e="" data-v-92417f3e="" class="text-muted">•</span> <a data-v-80e5955e="" data-v-92417f3e="" class="sharing-item"><i data-v-80e5955e="" data-v-92417f3e="" aria-hidden="true" class="fa fa-google-plus"></i></a></div></div></div></div> <footer id="footer" class="footer bg-dark"><div class="container pt-2"><div class="row"><div class="mb-1 mb-md-0 col-md-4"><h4 class="footer__header">
                    Tài nguyên
                </h4> <ul class="list-unstyled footer__links resources"><li><a href="https://viblo.asia/" class="link active">
                            Bài viết
                        </a></li> <li><a href="https://viblo.asia/organizations" class="link">
                            Tổ chức
                        </a></li> <li><a href="https://viblo.asia/questions" class="link">
                            Câu hỏi
                        </a></li> <li><a href="https://viblo.asia/tags" class="link">
                            Tags
                        </a></li> <li><a href="https://viblo.asia/videos" class="link">
                            Videos
                        </a></li> <li><a href="https://viblo.asia/authors" class="link">
                            Tác giả
                        </a></li> <li><a href="https://viblo.asia/discussion" class="link">
                            Thảo luận
                        </a></li> <li><a href="https://viblo.asia/explore" class="link">
                            Đề xuất hệ thống
                        </a></li> <li><a href="https://about.viblo.asia/tools/" target="_blank" rel="noopener" class="link">Công cụ</a></li> <li><a href="https://machine-learning.viblo.asia/" target="_blank" rel="noopener" class="link">Machine Learning</a></li> <li><a href="https://status.viblo.asia/" target="_blank" rel="noopener" class="link">Trạng thái hệ thống</a></li></ul></div> <div class="mb-1 mb-md-0 col-md-3 offset-xl-1"><h4 class="footer__header">
                    Dịch vụ
                </h4> <ul class="list-unstyled footer__links service-badges"><div class="row"><div class="col-xs-12 col-sm-3 col-md-12 col-lg-12 col-xl-12"><li class="footer__links__external-link"><a href="https://code.viblo.asia/" target="_blank" rel="noopener" class="link"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/viblo-code.png" alt="Viblo CV" width="24" height="24" class="link-icon">
                                    Viblo Code
                                </a></li></div> <div class="col-xs-12 col-sm-3 col-md-12 col-lg-12 col-xl-12"><li class="footer__links__external-link"><a href="https://cv.viblo.asia/" target="_blank" rel="noopener" class="link"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/viblo-cv.png" alt="Viblo CV" width="24" height="24" class="link-icon">
                                    Viblo CV
                                </a></li></div> <div class="col-xs-12 col-sm-3 col-md-12 col-lg-12 col-xl-12"><li class="footer__links__external-link"><a href="https://ctf.viblo.asia/" target="_blank" rel="noopener" class="link"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/viblo-ctf.png" alt="Viblo CTF" width="24" height="24" class="link-icon">
                                    Viblo CTF
                                </a></li></div> <div class="col-xs-12 col-sm-3 col-md-12 col-lg-12 col-xl-12"><li class="footer__links__external-link"><a href="https://learn.viblo.asia/" target="_blank" rel="noopener" class="link"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/viblo-learn.png" alt="Viblo Learning" width="24" height="24" class="link-icon">
                                    Viblo Learning
                                </a></li></div></div></ul></div> <div class="mb-1 mb-md-0 col-md-3 offset-md-1"><div class="d-flex align-items-baseline"><h4 class="footer__header mr-1">
                        Ứng dụng di động
                    </h4></div> <div class="d-flex mobile-app-badges mb-05"><div class="d-flex flex-md-column justify-content-between flex-wrap"><a href="https://play.google.com/store/apps/details?id=com.framgia.viblo.android.prod" target="_blank" rel="noopener" class="d-block"><img alt="Get it on Google Play" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/en_badge_web_generic.png" width="646" height="250" class="play-store-badge"></a> <a href="https://itunes.apple.com/us/app/viblo/id1365286437" target="_blank" rel="noopener" class="d-block"><img alt="Download on the App Store" src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/app-store-badge.8c4986ee4828b47d16f5cd694ef065f2.svg" width="646" height="250" class="app-store-badge"></a></div> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHwAAAB8CAIAAAAkfEPpAAACEklEQVR42u3aUY6DMAwFQO5/6e4JKhXF7yUL488KBZhEcm1zfUQ9LgTQoYsC+hWIb+t/faCb19x9hp9Q0g7QoUOHXkZfShRDL/wLxMp9p9a5vT506NChb0RPJ8yVNaeSc9MBOnTo0N+CvgKdKI6gQ4cOHfoMysrzJBpz0KFDh/4E9EQimmqcJYqmR3UZoUOHDn1jgjrt98d+DQAdOvTHozcjsZGJxlzk3aFDhw69jN5Mqol10odjrDiCDh069DL6yjXpYfTUvarFIHTo0KEX0KcGAlMD6MSgIz0Qv10cQYcOHXoBfaphlG5UNRPs2AGFDh069I3oTaxE46xZfI19DQAdOnTog+iJwmQlwSaKo+ahgQ4dOvTT0acKimaynTpMS4cAOnTo0AvozRdrbmT6cNz+EwEdOnToG9F3DSjSSb45DIEOHTr0NnpiEJwoRtKIiaEKdOjQoZ+Inn7QxMZMDVjGng06dOjQD0FPFDVTiTqNODU0hw4dOvRT0CMNoOKHPitF1timQocOHXoBPR1TELuG6ZGGF3To0KEXvk+fiubQ+YRCb+nfC3To0KGH0BMJMz3QmDociQIQOnTo0E9BTyfM9NAg0fBa2jzo0KFDfxj6rmsSGwkdOnTob0dPI6Ybdo8qjqBDh/4q9PRgYaqQSQ/QoUOHDv2/oqcbQFPJNp14E4cJOnTo0BvoohPQoUMXofgD+J8kMHoXlkcAAAAASUVORK5CYII=" width="124" height="124" alt="QR code" class="qr hidden-md-down"></div> <h4 class="footer__header">
                    Liên kết
                </h4> <ul class="list-unstyled footer__social-links"><li class="footer__socail-links__external-link"><a href="https://www.facebook.com/viblo.asia/" target="_blank" rel="noopener" class="link"><i class="fa fa-facebook link-icon"></i></a></li> <li class="footer__socail-links__external-link"><a href="https://github.com/viblo-asia/" target="_blank" rel="noopener" class="link"><i class="fa fa-github link-icon"></i></a></li> <li class="footer__socail-links__external-link"><a href="https://chrome.google.com/webstore/detail/viblos-news-feed/mliahmjgdpkkicelofhbhgiidgljijmj" target="_blank" rel="noopener" class="link"><i class="fa fa-chrome link-icon"></i></a></li> <li class="footer__socail-links__external-link"><a href="https://atom.io/packages/viblo" target="_blank" rel="noopener" class="link"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/atom-editor.svg" alt="Atom Icon" width="24" height="24" class="link-icon"></a></li></ul></div></div> <hr class="footer__divider"> <div class="row py-1"><div class="mt-0 col-xs-12 col-sm-12 col-lg-3 col-xl-4"><div class="d-flex align-items-center" style="height:100%;"><div class="el-select language-switcher el-select--small"><!----><div class="el-input el-input--small el-input--prefix el-input--suffix"><!----><input type="text" readonly="readonly" autocomplete="off" placeholder="Select" class="el-input__inner"><span class="el-input__prefix"><i class="fa fa-globe lead text-body"></i><!----></span><span class="el-input__suffix"><span class="el-input__suffix-inner"><i class="el-select__caret el-input__icon el-icon-arrow-up"></i><!----><!----><!----><!----><!----></span><!----></span><!----><!----></div><div class="el-select-dropdown el-popper" style="display: none; min-width: 209px;"><div class="el-scrollbar" style=""><div class="el-select-dropdown__wrap el-scrollbar__wrap" style="margin-bottom: -17px; margin-right: -17px;"><ul class="el-scrollbar__view el-select-dropdown__list"><!----> <li class="el-select-dropdown__item selected"><span>Tiếng Việt</span></li><li class="el-select-dropdown__item"><span>English</span></li></ul></div><div class="el-scrollbar__bar is-horizontal"><div class="el-scrollbar__thumb" style="transform: translateX(0%);"></div></div><div class="el-scrollbar__bar is-vertical"><div class="el-scrollbar__thumb" style="transform: translateY(0%);"></div></div></div><!----></div></div></div></div> <div class="col-xs-12 col-sm-12 col-lg-9 col-xl-8"><ul class="list-unstyled d-flex justify-content-md-between justify-content-lg-end flex-wrap justify-content-sm-start"><li class="mb-05 mx-05"><a href="https://about.viblo.asia/" target="_blank" rel="noopener" class="link">Về chúng tôi</a></li> <li id="v-step-4" class="mb-05 mx-05"><a href="https://viblo.asia/feedback" class="link">Phản hồi</a></li> <li class="mb-05 mx-05"><a href="https://viblo.asia/helps" class="link">
                            Giúp đỡ
                        </a></li> <li class="mb-05 mx-05"><a href="https://viblo.asia/faq" class="link">
                            FAQs
                        </a></li> <li class="mb-05 mx-05"><a href="https://viblo.asia/rss-channels" class="link">
                            RSS
                        </a></li> <li class="mb-05 mx-05"><a href="https://viblo.asia/terms/vi" class="link">
                            Điều khoản
                        </a></li> <li class="mb-05 mx-05"><a href="https://www.dmca.com/Protection/Status.aspx?ID=41818fcd-5a60-4504-867a-38fde606354e&amp;refurl=https://viblo.asia/p/xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3" title="DMCA.com Protection Status" target="_blank" rel="noopener" class="link dmca-badge"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/dmca-badge-w100-5x1-07.png" alt="DMCA.com Protection Status" width="100" height="20"></a> <script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/DMCABadgeHelper.min.js.download"></script></li> <li class="mb-05 mx-05">
                        © <b>Viblo</b> 2021
                    </li></ul></div></div></div> <!----></footer> <!----> <a id="top-btn" href="javascript:void(0);" class="hidden-sm-down"><i aria-hidden="true" class="fa fa-arrow-up"></i></a> <!----> <div class="fixed-bottom-bar fixedBottombar"><div class="wrapper d-flex"><div class="logo-bottom"><img src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/favicon-white-128.png" alt="Viblo"></div> <div class="content d-flex flex-column"><div class="text"><span class="text-register">
                    Hãy đăng ký một tài khoản Viblo để nhận được nhiều bài viết thú vị hơn.
                </span></div> <div class="button d-flex mt-1"><button class="login-button">
                    Đăng nhập
                </button> <a href="https://accounts.viblo.asia/register" class="register-button">
                    Đăng kí
                </a></div></div> <div class="icon-close" style="cursor:pointer"><i class="icon fa fa-close"></i></div></div></div></div></div></div><script>window.__NUXT__=(function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D){return {layout:f,data:[{}],fetch:{},error:a,state:{announcements:{indicator:d,items:[],processing:b,pinnedItem:a,post:{},related:[]},auth:{user:a,roles:a,lastSeens:a,guest:c,showAuthDialog:b,showLetRegister:c,reminderLogin:b,avtUser:l},badges:{items:{}},bookmarks:{bookmarks:a,pagination:a,type:"posts"},commentsList:{comments:{},pagination:{}},config:{analytics_track_id:"UA-88817199-1",banners:[{name:"Viblo Contribution Event 2021",image:"https:\u002F\u002Fimages.viblo.asia\u002Ffull\u002F688a2cf2-99b3-481c-abbe-16000a16c68b.png",link:"https:\u002F\u002Fcontribute.viblo.asia?utm_source=viblo&utm_medium=announcement&utm_campaign=viblo_contribution_event_2021",active:c,background_color:"#5C8AC5"},{name:"Viblo Code",image:"https:\u002F\u002Fimages.viblo.asia\u002Ffull\u002Fbf6fd90b-e818-4cb4-a025-0ffe3f915ef0.png",link:"https:\u002F\u002Fcode.viblo.asia",background_color:"#5488c7",active:c},{name:"Viblo CTF",link:"https:\u002F\u002Fctf.viblo.asia",image:"https:\u002F\u002Fimages.viblo.asia\u002Ffull\u002Ff6e3d256-a4d4-4751-8fc6-895e53f6c74f.jpg",active:c,background_color:"#4878bf"},{name:"Viblo Learning",image:"https:\u002F\u002Fimages.viblo.asia\u002Ffull\u002F3319dbd3-c918-4bb1-beee-21097403ec01.jpg",link:"https:\u002F\u002Flearn.viblo.asia\u002F?utm_source=viblo&utm_medium=announcement&utm_campaign=release_viblo_learning",active:c,background_color:"#0b1a33"}],currentBannerIndex:h,motd:[{text:"\u003E\u003E Tham gia Facebook group \"Viblo Community\" để cùng nhau học tập và kết nối \u003C\u003C",link:"https:\u002F\u002Ffacebook.com\u002Fgroups\u002Fviblo.community.official"}],currentMotdIndex:a,currentBgIndex:a},hovercard:{all:{}},notifications:{data:[],batch:d,lastBatch:1,unread:d},oneTap:{isDisplayed:b,isSkipped:b},organizationsUser:{organizations:[]},pageHistory:{current:{path:i,hash:m,params:{post:"xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3"},fullPath:i},previous:a},postHomeFeed:{byId:{},all:[],pagination:{},sidebar:{users:[],questions:[],organizations:[]}},postView:{post:{id:n,slug:o,transliterated:p,user_id:j,contents:"# Hệ thống kiểm soát nhận dạng khuôn mặt là gì?\n![](https:\u002F\u002Fimages.viblo.asia\u002F1c2afe28-51e3-419e-b038-3340593e56a0.jpg)\n\nVào thời điểm mình viết bài viết này, chắc hẳn cụm từ **NHẬN DẠNG KHUÔN MẶT (FACIAL RECOGNITION)** đã không còn là một khái niệm quá xa lạ đối với bất kỳ một ai. Đây là một kỹ thuật nhằm xác định một người từ một hình ảnh hoặc một khung hình trong video lấy được. Công nghệ nhận diện khuôn mặt giờ đã trở nên rất quen thuộc, và được áp dụng phổ biến trong các hệ thống an ninh ở nhiều nơi trên thế giới, trong đó có cả Việt Nam.\n\nƯu điểm của công nghệ này so với các công nghệ nhận dạng khác (nhận dạng vân tay, nhận dạng giọng nói, nhận dạng mống mắt) chính là việc **nó không đòi hỏi sự hợp tác đến từ người dùng**. \n\n\u003Cbr\u003E\n\n# Mục tiêu\nHiện nay có rất nhiều kỹ thuật để thực hiện việc nhận dạng khuôn mặt, tuy nhiên điểm chung của các kỹ thuật này là đều sẽ phải thực hiện qua 3 bước: \n1. Xác định và lấy ra (các) khuôn mặt có trong hình ảnh\n2. Từ hình ảnh các khuôn mặt lấy ra từ bước 1, thực hiện việc phân tích, trích xuất các đặt trưng của khuôn mặt\n3. Từ các thông tin có được sau khi phân tích, kết luận và xác minh danh tính người dùng\n\nThông qua bài viết lần này, mình sẽ xây dựng một hệ thống hoàn chỉnh cho việc nhận dạng khuôn mặt dựa vào thư viện Dlib của OpenCV và mạng Deep Learning sử dụng hàm Triplet Loss. Hy vọng sẽ giúp các bạn nắm được công nghệ này để có thể tự triển khai được trong thực tế.\n\n# Xây dựng hệ thống nhận dạng khuôn mặt\nMột chút đọc lại trong phần ngay trước, mình đã nói về 3 bước thực hiện của một hệ thống nhận dạng khuôn mặt, và giờ chúng ta sẽ thực hiện đầy đủ 3 bước đó nhé.\n\n## Xác định khuôn mặt trong ảnh (Facial detection) - Việc khó đã có Dlib lo\n![](https:\u002F\u002Fimages.viblo.asia\u002Fd3c5f6e9-cd20-4004-9d5f-5d18c821f0b7.jpg)\nĐiều cần làm đầu tiên với bức ảnh\u002F khung hình chúng ta có đó chính là xác định xem trong bức ảnh\u002F khung hình đó có sự xuất hiện của bao người khuôn mặt (bao nhiêu người) và vị trí của chúng trong bức ảnh. Bài toán trở nên rất giống với bài toán xác định vật thể (Object Detection). Đây là một trong những bài toán rất khó bởi chúng ta sẽ cần nhiều kinh nghiệm cũng như lý thuyết về xử lý ảnh để có thể giải quyết được bước này. Cụ thể hơn, một số kỹ thuật cho bài toán này có thể kể đến như:\n1. **Kỹ thuật xác định dựa vào các kiến thức con người (Knowledge-based)**: Kỹ thuật này dựa vào các hiểu biết của con người về khuôn mặt để xác định được một khuôn mặt trong ảnh (Ví dụ như việc một khuôn mặt sẽ phải có mắt, mũi, miệng và khoảng cách giữa chúng thường sẽ phải thoả mãn các ràng buộc nào đó,..). Điểm khó của kỹ thuật này nằm ở việc chúng ta sẽ phải xây dựng nên 1 bộ quy tắc. Nếu bộ quy tắc quá chung chung hay quá chặt chẽ thì đều không được vì nó sẽ dẫn tới việc nhận dạng nhầm hoặc không nhận dạng được.\n2. **Kỹ thuật xác định dựa vào đặc tính khuôn mặt (Feature-based)**: Kỹ thuật này tạo ra một mô hình, sau đó chúng ta sẽ huấn luyện mô hình đó như một mô hình để phân loại (classifier) nhằm xác định trong các khung hình cắt ra từ 1 ảnh ban đầu, đâu là các vùng của một khuôn mặt. Điểm yếu lớn nhất của kỹ thuật này là về mặt thời gian. Có vấn đề này là do chúng ta sẽ phải lấy ra rất nhiều vùng trong 1 bức ảnh nhằm đưa qua classifier.\n3. **Kỹ thuật xác định dựa vào mẫu cho trước (Template-Matching)**: Kỹ thuật này xác định được vị trí của một khuôn mặt trong bức ảnh dựa vào việc so sánh giữa các bức ảnh khuôn mặt chúng ta cho trước (Feature template) và các khung hình được cắt ra. Template-Matching rất dễ dàng để sử dụng tuy nhiên cũng gặp phải vấn đề về thời gian tương tự như kỹ thuật Feature-base ở trên.\n4. **Kỹ thuật xác định dựa vào hình dáng (Appearance-Base)**: Đây là kỹ thuật mà Dlib sẽ sử dụng, phương pháp sử dụng các phương pháp hình thái học kết hợp với phân tích từ mô hình machine-leanring để xác định trực tiếp về vị trí của các vùng có khuôn mặt trong ảnh. Chúng ta sẽ nói kỹ hơn nữa về kỹ thuật này ở phần sau.\n\nTin vui cho các bạn là chúng ta sẽ không cần phải hiểu tất cả, thậm chí cũng không cần nắm quá rõ về một kỹ thuật nào trong số các kỹ thuật trên mà vẫn có thể thực hiện được dễ dàng bước này.\n\n![](https:\u002F\u002Fimages.viblo.asia\u002F9cab529c-4286-49f5-a962-bfacaf885667.jpg)\n\nĐúng như tiêu đề của mình có ghi, mọi việc khó nhất của bước này, chúng ta đều sẽ \"nhờ\" Dlib giải quyết! **Dlib là một chương trình của thư viện OpenCV, hỗ trợ người dùng trong việc xác định khuôn mặt**.\nThuật toán mà Dlib sử dụng đó là HOG (Histogram of Oriented Gradients) và SVM (Support Vector Machine), đây chính là lý do tại sao Dlib có thời gian chạy rất nhỏ và có thể sử dụng trong các hệ thống thời gian thực. Tuy nhiên gần đây, Dlib cũng đã cung cấp thêm các hàm xác định khuôn mặt dựa trên mạng CNN nên tiếp theo chúng ta sẽ cùng thử cả 2 phương pháp này nhé. Tất cả sẽ có trong đoạn code dưới đây.\n\n```python\nimport time\nimport dlib\nimport cv2\n\n# Đọc ảnh đầu vào\nimage = cv2.imread('\u002FUsers\u002Fphamhoanganh\u002FDesktop\u002F2.jpg')\n\n# Khai báo việc sử dụng các hàm của dlib\nhog_face_detector = dlib.get_frontal_face_detector()\ncnn_face_detector = dlib.cnn_face_detection_model_v1('\u002FUsers\u002Fphamhoanganh\u002FDesktop\u002Fmmod_human_face_detector.dat')\n\n# Thực hiện xác định bằng HOG và SVM\nstart = time.time()\nfaces_hog = hog_face_detector(image, 1)\nend = time.time()\nprint(\"Hog + SVM Execution time: \" + str(end-start))\n\n# Vẽ một đường bao màu xanh lá xung quanh các khuôn mặt được xác định ra bởi HOG + SVM\nfor face in faces_hog:\n  x = face.left()\n  y = face.top()\n  w = face.right() - x\n  h = face.bottom() - y\n\n  cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,0), 2)\n\n# Thực hiện xác định bằng CNN\nstart = time.time()\nfaces_cnn = cnn_face_detector(image, 1)\nend = time.time()\nprint(\"CNN Execution time: \" + str(end-start))\n\n# Vẽ một đường bao đỏ xung quanh các khuôn mặt được xác định bởi CNN\nfor face in faces_cnn:\n  x = face.rect.left()\n  y = face.rect.top()\n  w = face.rect.right() - x\n  h = face.rect.bottom() - y\n\n  cv2.rectangle(image, (x,y), (x+w,y+h), (0,0,255), 2)\n\ncv2.imshow(\"image\", image)\ncv2.waitKey(0)\n```\n\nĐi qua một chút về đoạn code trên. Đầu tiên, hãy chắc chắn rằng các bạn đã cài đặt Dlib và thực hiện import. \n```\npip install dlib\n```\nChi tiết hơn về cách cài đặt, các bạn hãy làm theo bài viết này\n\u003E https:\u002F\u002Fwww.learnopencv.com\u002Finstall-dlib-on-ubuntu\u002F\n\n\u003Cbr\u003E\n\nTiếp theo, mình đọc vào một ảnh bất kỳ, sau đó gán và khai báo các hàm xác định khuôn mặt của Dlib.\n- dlib.get_frontal_face_detector: hàm sử dụng HOG + SVM để xác định khuôn mặt\n- dlib.cnn_face_detection_model_v1: hàm sử dụng CNN để xác định khuôn mặt, tuy nhiên để sử dụng được hàm này ngay mà không cần huấn luyện lại, chúng ta cần phải load weights của mạng CNN đã được train trước. Các bạn có thể tải xuống weights ở đây và thực hiện khai báo như mình ở trên nhé.\n\u003E http:\u002F\u002Farunponnusamy.com\u002Ffiles\u002Fmmod_human_face_detector.dat\n\n\u003Cbr\u003E\n\nĐây là bức ảnh mà mình sẽ sử dụng để thử\n![](https:\u002F\u002Fimages.viblo.asia\u002F4cefa08f-c6b1-4b37-abff-69205b73a144.jpg)\n\nTiếp đến, chúng ta thực hiện việc gọi hàm xác định khuôn mặt. Ở đây, để so sánh 2 phương pháp, trước và sau mỗi khi thực hiện hàm xác định của mỗi phương pháp, mình đầu ghi lại thời gian để tiện cho việc so sánh sau này. \n```python\nfaces_hog = hog_face_detector(image, 1)\nfaces_cnn = cnn_face_detector(image, 1)\n```\nTham số cần truyền vào cả 2 hàm đều là ảnh đầu vào và số lượng của cửa sổ tìm kiếm. Nếu số này càng lớn, đồng nghĩa với việc sẽ có thêm các cửa sổ tìm kiếm (kích thước cửa sổ mới sẽ nhỏ dần). Điều này giúp ta nhận ra được các khuôn mặt ở xa (bị nhỏ) ở trong ảnh tuy nhiên đánh đổi bằng việc thời gian chạy sẽ tăng theo cấp số mũ. Ở đây mình chỉ để 1 cửa sổ. \n\nCả 2 hàm đều trả về cho chúng ta 1 list các toạ độ của các khuôn mặt có trong ảnh, và từ đó mình sẽ thực hiện vẽ lên ảnh các đường bao chữ nhật. \n\n**LƯU Ý**: Để phân biệt thì đối với các khuôn mặt được xác định nhờ HOG+SVM, mình sẽ vẽ đường bao màu xanh, còn các vùng được xác định nhờ CNN, mình sẽ vẽ đường bao màu đỏ! Hãy cùng xem kết quả.\n![](https:\u002F\u002Fimages.viblo.asia\u002F924f1337-a96a-4c42-a24b-9cf22273fbdf.jpg)\nDễ thấy rằng CNN cho ta kết quả gần như tuyệt đối, còn đối với phương pháp HOG kết hợp SVM, chúng ta hãy để ý những trường hợp phương pháp này không xác định được... Chắc các bạn cũng đều nhận ra, HOG+SVM bị bỏ qua các khuôn mặt quay nghiêng góc hoặc bị che một phần. Điều này đúng với tên hàm mà Dlib cung cấp cho chúng ta **get_frontal_face_detector**!!\n\nTuy nhiên trước khi buông lời phán xét, hãy xem thêm thông số về thời gian mà mình cho in ra\n\u003E Hog + SVM Execution time: 0.1367199420928955\u003Cbr\u003E\n\u003E CNN Execution time: 4.2889978885650635\n\u003E \nVới một bức ảnh khoảng 800x600 pixel như thế này, phương pháp sử dụng HOG kết hợp SVM mất khoảng 0.13 giây để xác định được toàn bộ khuôn mặt, còn phương pháp CNN lại phải mất tới 4.29 giây (gấp khoảng 40 lần). Sự chênh lệch này sẽ lớn hơn rất nhiều nếu chúng ta thử trên một bức ảnh chất lượng cao hơn. Tuy nhiên do hiện nay mình đang sử dụng MBP2017 là 1 loại máy không hỗ trợ về tính toán, GPU quá mạnh nên phương pháp CNN tỏ ra kém hiệu quả. Vậy nên với \"cơ sở vật chất\" của mình thì mình sẽ chọn sẽ dụng phương pháp HOG + SVM để đảm bảo được hệ thống của mình sẽ hoạt động được với **thời gian thực** nhé!!\n\n\u003Cbr\u003E\n\nĐến đây, chúng ta đã xử lý xong bước đầu tiên theo một cách ... rất dễ dàng và tiện lợi nhờ sự hỗ trợ của DLIB. Hệ thống của chúng ta đã có thể xác định được các vị trị khuôn mặt ở trong ảnh! Ngoài ra, Dlib còn hỗ trợ chúng ta lấy ra các điểm quan trọng trên khuôn mặt (Landmark), tuy nhiên mình sẽ không đề cập tới trong bài viết này vì hệ thống chúng ta đang xây dựng hoàn toàn không sử dụng chúng.\n\n## Biểu diễn các khuôn mặt dưới dạng vector\nNói đến việc nhận dạng, xác định khuôn mặt này là \"của ai\", chúng ta sẽ cần tính độ GIỐNG\u002F KHÁC nhau giữa các khuôn mặt chúng ta lấy được. Và nói về độ GIỐNG\u002F KHÁC nhau, để đơn giản, chúng ta sẽ quy về bài toán **Tính khoảng cách giữa các vector**. Dù là trong xử lý âm thanh hay xử lý ảnh hay xử lý ngôn ngữ tự nhiên, việc chuyển về vector để tính khoảng cách đều là một lựa chọn rất tốt. Và trong bài viết này, mình sẽ biến các khung hình khuôn mặt về các vector có 128 chiều (số chiều này là do sau nhiều lần mình thử và chọn ra, các bạn có thể thử và lựa chọn số khác).\n\nVề lý thuyết thì là như vậy, nhưng vấn đề quan trọng nhất ở đấy chính là\n\u003E **CẦN MỘT MÔ HÌNH CHUYỂN TỪ KHUNG HÌNH KHUÔN MẶT SANG VECTOR, SAO CHO ẢNH 2 KHUÔN MẶT GẦN NHAU THÌ 2 VECTOR TƯƠNG ỨNG CŨNG PHẢI CÓ KHOẢNG CÁCH GẦN NHAU. ẢNH 2 KHUÔN MẶT KHÁC NHAU THÌ 2 VECTOR TƯƠNG ỨNG CŨNG PHẢI XA NHAU HƠN.**\n\nVà để giải quyết vấn đề này, mình sẽ giới thiệu cho các bạn mô hình học sâu ConvNet sử dụng hàm loss Triplet.\n\n### Triplet là gì?\nTiếng việt của Triplet có thể tạm được dịch ra là \"bộ ba\". Với rất nhiều các bài toán khác trước đây của các mô hình học sâu, thông thường chúng ta sẽ cho lần lượt từng ảnh một vào để mô hình học, tuy nhiên với bài toán lần này, chúng ta sẽ phải sử dụng từng \"bộ ba\". \n\nBộ ba của chúng ta bao gồm: 1 ảnh mặt của 1 người bất kỳ (query), 1 ảnh mặt khác của người đó (positive), 1 ảnh mặt của người khác (negative). Với việc huấn luyện mô hình như thế, chúng ta sẽ có thêm thông tin về mối quan hệ giữa các ảnh, điều này giúp mô hình chúng ta phù hợp hơn nhiều với bài toán.\n\n### ConvNet\n![](https:\u002F\u002Fimages.viblo.asia\u002F7f274c8c-a2ba-400f-bf2a-180c7c3b4804.png)\nĐây là một mạng học sâu với cấu trúc 3 nhánh. Với 1 ảnh đưa vào, chúng ta sẽ thu được 1 vector cuối cùng đầu ra (Trong ảnh là 4096 chiều, còn mình sẽ đưa về 128 chiều). Điểm khác ở đây là ảnh sẽ được phân tích theo 3 mô hình khác nhau, mô hình đã được chứng minh hiệu quả trong nhiều bài toán\u002F cuộc thi xử lý ảnh khác. Vậy nên chúng ta sẽ sử dụng ConvNet trên trong bài toán lần này.\n\n### Triplet loss\nMột lần nữa\n\u003E **CẦN MỘT MÔ HÌNH CHUYỂN TỪ KHUNG HÌNH KHUÔN MẶT SANG VECTOR, SAO CHO ẢNH 2 KHUÔN MẶT GẦN NHAU THÌ 2 VECTOR TƯƠNG ỨNG CŨNG PHẢI CÓ KHOẢNG CÁCH GẦN NHAU. ẢNH 2 KHUÔN MẶT KHÁC NHAU THÌ 2 VECTOR TƯƠNG ỨNG CŨNG PHẢI XA NHAU HƠN.**\n\nVậy làm sao mô hình của chúng ta hiểu được điều này khi huấn luyện để có thể giúp chúng ta tạo ra các vector như ý? Đây chính là lúc việc sử dụng \"bộ ba\" trở nên hiệu quả. Và hàm loss của mô hình chúng ta sẽ có dạng như sau\n![](https:\u002F\u002Fimages.viblo.asia\u002F3fbe06b0-8023-4ad0-96ae-0781c86193c1.png)\n\nVới $f(p)$ là vector biểu diễn $p$.  $D$ là khoảng cách giữa 2 vector. Hàm loss của chúng ta sẽ là [$-l]$. Nhìn qua một chút, chúng ta đang huấn luỵên để cho hàm trên  **CÀNG LỚN CÀNG TỐT (max)**. Điều này có nghĩa là mô hình chúng ta sẽ cố gắng học sao cho càng ngày, nó càng giảm khoảng cách giữa 2 vector $f(p_i)$ (Query Image) và $f(p_i^+)$ (Positive Image), và tăng khoảng cách giữa Query Image và Negative Image! Đây là điều chúng ta đang muốn mô hình học được\n\n### Chuẩn bị dữ liệu huấn luyện mô hình\nĐối với tuỳ từng tổ chức, mục đích sử dụng, chúng ta nên có 1 tập dữ liệu đặc thù, nhưng ở đây mình đang mô phỏng lại một hệ thống, vậy nên mình sẽ sử dụng 1 bộ data lớn một chút để thử nghiệm. Và ở đây mình chọn thử nghiệm hệ thống trên tập Labeled Face in Wild (LFW). Dataset này bao gồm hơn 13000 ảnh mặt người (được gán nhãn) thu thập trên mạng internet. Các bạn có thể tìm thấy bộ dữ liệu này ở đây\n\n\u003Cbr\u003E\n\nLFW Dataset: http:\u002F\u002Fvis-www.cs.umass.edu\u002Flfw\u002F\n\n### Huấn luyện mô hình\n```python\ndef convnet_model_():\n    vgg_model = applications.VGG16(weights=None, include_top=False, input_shape=(221, 221, 3))\n    x = vgg_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(4096, activation='relu')(x)\n    x = Dropout(0.6)(x)\n    x = Dense(4096, activation='relu')(x)\n    x = Dropout(0.6)(x)\n    x = Lambda(lambda x_: K.l2_normalize(x,axis=1))(x)\n#     x = Lambda(K.l2_normalize)(x)\n    convnet_model = Model(inputs=vgg_model.input, outputs=x)\n    return convnet_model\n\ndef deep_rank_model():\n    convnet_model = convnet_model_()\n\n    first_input = Input(shape=(221, 221, 3))\n    first_conv = Conv2D(96, kernel_size=(8,8), strides=(16,16), padding='same')(first_input)\n    first_max = MaxPool2D(pool_size=(3,3), strides=(2,2), padding='same')(first_conv)\n    first_max = Flatten()(first_max)\n    first_max = Lambda(lambda x: K.l2_normalize(x, axis=1))(first_max)\n\n    second_input = Input(shape=(221, 221, 3))\n    second_conv = Conv2D(96, kernel_size=(8,8), strides=(32,32), padding='same')(second_input)\n    second_max = MaxPool2D(pool_size=(7,7), strides=(4,4), padding='same')(second_conv)\n    second_max = Flatten()(second_max)\n    second_max = Lambda(lambda x: K.l2_normalize(x, axis=1))(second_max)\n                       \n    merge_one = concatenate([first_max, second_max])\n    merge_two = concatenate([merge_one, convnet_model.output])\n    emb = Dense(4096)(merge_two)\n    emb = Dense(128)(emb)\n    l2_norm_final = Lambda(lambda x: K.l2_normalize(x, axis=1))(emb)\n                        \n    final_model = Model(inputs=[first_input, second_input, convnet_model.input], outputs=l2_norm_final)\n\n    return final_model\n```\n```python\ndeep_rank_model = deep_rank_model()\n```\n\n\nMình xây dựng theo đúng mô hình ConvNet đã nói ở trên, 1 ảnh sẽ được đưa vào 3 đường khác nhau, trước khi nối lại để tạo thành 1 vector 128 chiều. Vector này sẽ đại diện cho bức ảnh, và khi mô hình được huấn luyện tốt, 128 thuộc tính này có thể coi như là 128 thuộc tính **đặc trưng** của khuôn mặt đó. Cũng vì đó, bước huấn luyện mô hình từ khuôn mặt sang vector còn gọi là bước **TRÍCH CHỌN ĐẶC TRƯNG**.\n\n\u003Cbr\u003E\n\nGiờ chúng ta sẽ code hàm triplet loss đúng theo công thức\n```python\nbatch_size = 24\n\n_EPSILON = K.epsilon()\ndef _loss_tensor(y_true, y_pred):\n    y_pred = K.clip(y_pred, _EPSILON, 1.0 - _EPSILON)\n    loss = 0.\n    g = 1.\n    for i in range(0, batch_size, 3):\n        try:\n            q_embedding = y_pred[i]\n            p_embedding = y_pred[i+1]\n            n_embedding = y_pred[i+2]\n            D_q_p = K.sqrt(K.sum((q_embedding - p_embedding)**2))\n            D_q_n = K.sqrt(K.sum((q_embedding - n_embedding)**2))\n            loss = loss + g + D_q_p - D_q_n\n        except:\n            continue\n    loss = loss\u002Fbatch_size*3\n    return K.maximum(loss, 0)\n```\n```python\ndeep_rank_model.compile(loss=_loss_tensor, optimizer=SGD(lr=0.001, momentum=0.9, nesterov=True))\n```\n\nMột điểm khác mà mình đã nói từ đầu trong việc huấn luyện mô hình này đó là việc chúng ta sẽ đưa ảnh theo BỘ BA. Và từ đó hàm loss cũng sẽ tính theo các BỘ BA, không phải tính riêng từng đầu ra như các mô hình khác. \n\n\u003Cbr\u003E\n\nĐây là cách mình chọn BỘ BA, ảnh đầu sẽ được coi là ảnh query, ảnh tiếp theo sẽ là positive (ảnh cùng class) và cuối cùng là ảnh negative (ảnh khác class)\n```python\ndef image_batch_generator(images, labels, batch_size):\n    labels = np.array(labels)\n    while True:\n        batch_paths = np.random.choice(a = len(images), size = batch_size\u002F\u002F3)\n        input_1 = []\n        \n        for i in batch_paths:\n            pos = np.where(labels == labels[i])[0]\n            neg = np.where(labels != labels[i])[0]\n            \n            j = np.random.choice(pos)\n            while j == i:\n                j = np.random.choice(pos)\n             \n            k = np.random.choice(neg)\n            while k == i:\n                k = np.random.choice(neg)\n            \n            input_1.append(images[i])\n            input_1.append(images[j])\n            input_1.append(images[k])\n\n        input_1 = np.array(input_1)\n        input = [input_1, input_1, input_1]\n        yield(input, np.zeros((batch_size, )))\n```\n\n```python\ndeep_rank_model.fit_generator(generator=image_batch_generator(X, y, batch_size),\n                   steps_per_epoch=len(X)\u002F\u002Fbatch_size,\n                   epochs=2000,\n                   verbose=1,\n                   callbacks=callbacks_list)\n```\n\n### Mô phỏng kết quả (Data Visualize)\nSau khi đã training xong, chúng ta muốn theo dõi kết quả 1 cách trực quan hơn. Liệu mô hình chúng ta có làm tốt được nhiệm vụ trích chọn đặc trưng, và khiến cho những khuôn mặt giống nhau thì về gần nhau, còn ngược lại thì xa nhau không? Để có thể **NHÌN RÕ ĐIỀU NÀY 1 CÁCH TRỰC QUAN**, chúng ta sẽ cần sử dụng thuật toán t-SNE. Thuật toán sẽ giúp chúng ta đưa từ không gian vector 128 chiều về không gian 3 chiều, giúp mắt ta quan sát dễ dàng nhất. Cụ thể về thuật toán và cách mô phỏng mình sẽ không đề cập ở đây, các bạn muốn tìm hiểu thêm, có thể đọc bài viết rất \"có tâm\" này của tác giả Phan Hoàng nhé:\n\n\u003Cbr\u003Ehttps:\u002F\u002Fviblo.asia\u002Fp\u002Fdata-visualization-voi-thuat-toan-t-sne-su-dung-tensorflow-projector-924lJAAzZPM\n\n\u003Cbr\u003E\n\nĐây là kết quả Visualize của mình:\n\u003Cbr\u003E\n\n![](https:\u002F\u002Fimages.viblo.asia\u002F09060172-06a8-472d-ba9b-507cd35bb1b9.gif)\n\nHoặc các bạn có thể xem trực tiếp tại: https:\u002F\u002Fhoanganhpham1006.github.io\u002Fface-detector-Visualize\u002F\n\nCác bạn hãy chọn t-SNE rồi đợi cho nó training khoảng 300-400 iter rồi dừng nhé. Việc training ở đây là training để đưa từ không gian 128 chiều về không gian 3 chiều, hoàn toàn không liên quan tới việc huấn luyện mình viết trong bài này\n\nDo mình training cũng chưa đủ lâu, nên các ảnh cũng chưa thực sự phân cụm 1 cách rõ ràng, tuy nhiên những ảnh cùng 1 người hoặc 2 người giống nhau đều nằm khá gần nhau trong không gian này!\n\n\u003Cbr\u003E\n\nVậy là chúng ta đã có một mô hình để chuyển từ ảnh khuôn mặt sang vector đúng theo ý đồ của chúng ta. Giờ chúng ta sẽ sang bước cuối cùng nhé!\n\n## Xác minh danh tính khuôn mặt\nCách đơn giản và không kém hiệu quả chính là tính khoảng cách Euclit của vector đặc trưng khuôn mặt đang cần nhận dạng với các vector đặc trưng khác, và lấy vector **GẦN NÓ NHẤT** làm kết quả xác minh\n\n```python\n# Với mỗi khung hình mặt phát hiện ra\n...\nframe = image[y:y+h, x:x+w]\nframe = cv2.resize(frame, (221, 221))\nframe = frame \u002F255.\nframe = np.expand_dims(frame, axis=0)\nemb128 = deep_rank_model.predict([frame, frame, frame])\nminimum = 99999\nperson = -1\nfor k, e in enumerate(embs128):\n    #Euler distance\n    dist = np.linalg.norm(emb128-e)\n    if dist \u003C minimum:\n        minimum = dist\n        person = k\ncv2.putText(image, names[person], (x - 10, y - 10),\n    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n```\n![](https:\u002F\u002Fimages.viblo.asia\u002F65f8c265-836b-4239-a09c-86dd69b15d23.jpg)\n\nNgoài ra để có thể tăng tính chính xác hơn nữa, các bạn hãy thêm 1 \"ngưỡng khoảng cách tối đa\". Nếu vector chúng ta cần xác định nằm quá xa so với các vector còn lại, thì khả năng cao chúng **không phải của người nào trong số dữ liệu chúng ta đang có**\n\n# Kết luận\nNhư vậy mình đã xây dựng xong hệ thống nhận dạng khuôn mặt của mình. Hy vọng các bạn sẽ có thể thực hiện theo và thành công! Mọi thắc mắc hãy để lại dưới comment nhé, mình rất sẵn lòng để giải đáp!\n\nLink source code: https:\u002F\u002Fgithub.com\u002Fhoanganhpham1006\u002Fface-detector\n\nCảm ơn các bạn đã quan tâm theo dõi",moderation:a,preview:{image:"https:\u002F\u002Fimages.viblo.asia\u002F1c2afe28-51e3-419e-b038-3340593e56a0.jpg",teaser:"Hệ thống kiểm soát nhận dạng khuôn mặt là gì?",contents:"Hệ thống kiểm soát nhận dạng khuôn mặt là gì?\n\nVào thời điểm mình viết bài viết này, chắc hẳn cụm từ NHẬN DẠNG KHUÔN MẶT (FACIAL RECOGNITION) đã không còn là một khái niệm quá xa lạ đối với bất kỳ một ai. Đây là một kỹ thuật nhằm xác định một người từ một hình ảnh hoặc một khung hình trong video lấy được. Công nghệ nhận diện khuôn mặt giờ đã trở nê..."},current_revision:a,reading_time:q,series_id:398,video_id:a,slide_url:m,organization:{data:{id:k,name:r,user_id:h,avatar:s,slug:t,following:b,followers_count:u,location:v,posts_count:w,website:a,website_verified:b,members_count:x,google_analytics_id:a,short_description:y,full_description:z,approved:c}},last_edited_at:"2018-12-10T23:08:02+07:00",puzzle_hash_id:a,license:"all_rights_reserved",seo_setting:{data:[]}},related:a,relatedOrganizations:a,fetchedAt:new Date(1634127196620),invalidated:b,series:a,proposals:[],video:a,tracking:a,comments:{byId:A,threads:B,loading:c}},profile:{profile:a,contact:{byId:A,threads:B,loading:c},followers:{current:[],pagination:{}},following:{current:[],pagination:{}},posts:{byId:{},all:[],pagination:{}},questions:{byId:{},current:[],pagination:{}},skills:{skills:[]}},promoted:{users:{},posts:[],tags:[],currentSharingId:a},questionHomeFeed:{sidebar:{users:[],posts:[]}},questionView:{question:a,answers:{byId:{},all:[]},subscribers:[],invalidated:c,comments:{byId:{},threads:{}}},seriesView:{series:{},posts:[],requests:[],seriesHome:a,paginationSeries:a,comments:{byId:{},threads:{}}},settings:{perPage:20,layout:"simple",theme:f,homepage:f},survey:{externalUrl:a},toast:{messages:[],newPosts:d},typeControl:{fontSize:18,lineHeight:1.75,fullScreen:b,modeTheme:f},userRankings:{current:[],byId:{}},vueTour:{step0:b,step1:b,step2:b,step3:b,step4:b,writePostStep0:b,writePostStep1:b,writePostStep2:b,writePostStep3:b,showBackgroud:b,triggerUserMenu:"click"},__modules:{comments:{},"post-feed":{},"question-feed":{byId:{},current:[],pagination:{}},"user-list":{current:[],pagination:{}}},__plugins:{pushNewPosts:{},pushNotifications:{}},__utils:{entities:{},schemas:{}},entities:{organizations:{all:{"96":{id:k,slug:t,user_id:h,avatar:s,name:r,posts_count:w,short_description:y,full_description:z,followers_count:u,members_count:x,following:b,location:v,website:a,website_verified:b,approved:c}}},posts:{all:{"25174":{id:n,slug:o,title:"Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning",transliterated:p,tags:{data:[{slug:"machine-learning",name:"Machine Learning"},{slug:"deep-learning",name:"Deep Learning"},{slug:"open-cv",name:"Open CV"}]},user_id:j,canonical_url:"https:\u002F\u002Fviblo.asia\u002Fp\u002Fxay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3",uploads:[{uuid:"1c2afe28-51e3-419e-b038-3340593e56a0",width:580,height:325,extension:e},{uuid:"d3c5f6e9-cd20-4004-9d5f-5d18c821f0b7",width:g,height:C,extension:e},{uuid:"9cab529c-4286-49f5-a962-bfacaf885667",width:516,height:389,extension:e},{uuid:"4cefa08f-c6b1-4b37-abff-69205b73a144",width:2048,height:1365,extension:e},{uuid:"924f1337-a96a-4c42-a24b-9cf22273fbdf",width:g,height:533,extension:e},{uuid:"7f274c8c-a2ba-400f-bf2a-180c7c3b4804",width:883,height:453,extension:D},{uuid:"3fbe06b0-8023-4ad0-96ae-0781c86193c1",width:928,height:78,extension:D},{uuid:"09060172-06a8-472d-ba9b-507cd35bb1b9",width:C,height:371,extension:"gif"},{uuid:"65f8c265-836b-4239-a09c-86dd69b15d23",width:g,height:g,extension:e}],status:"public",promoted:b,trending:b,organization:{data:k},views_count:20179,clips_count:21,comments_count:45,clipped:b,points:29,rated_value:a,created_at:"2018-12-05T22:40:03+07:00",updated_at:"2021-10-13T19:00:01+07:00",published_at:"2018-12-10T22:22:54+07:00",reading_time:q,can_share_social:c}}},questions:{all:{}},tags:{all:{}},users:{all:{"19902":{id:j,username:"hoanganhpham",name:"Phạm Hoàng Anh",avatar:l,following:b,reputation:3200,followers_count:211,posts_count:15,questions_count:d,answers_count:d,banned_at:a}}}},organizationView:{followers:{current:[],pagination:{}},members:{current:[],pagination:{}},technologyStacks:{technologies:[]}},tagView:{followers:{current:[],pagination:{}},posts:{byId:{},all:[],pagination:{}},questions:{byId:{},current:[],pagination:{}}},writeups:{puzzlePosts:{byId:{},all:[],pagination:{},puzzle:a}},i18n:{locale:"en"}},serverRendered:c,routePath:i,config:{_app:{basePath:"\u002F",assetsPath:"\u002F_nuxt\u002F",cdnURL:a}}}}(null,false,true,0,"jpg","default",800,2,"\u002Fp\u002Fxay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3",19902,96,"f4849a25-3687-49cb-ab03-53c9597435f0.jpg","",25174,"4P8566ma5Y3","xay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning",22,"Sun* AI Research Team","c2739118-a46f-4c47-96ba-c7e8a4781b18.jpg","sun-ai-research-team",520,"Sun* R&D Lab",321,32,"We're AI Research Team of R&D Lab @Sun Asterisk .Inc","## Who we are?\nWe are AI Research Team, from R&D Unit of [Sun Asterisk](https:\u002F\u002Fsun-asterisk.com). We are a creative and dynamic team with about 20 members spending fulltime on researching the newest technologies and developing our own products.\n\n## What we do?\n* Research about Machine Learning, Deep Learning Algorithms.\n* Apply Machine Learning into projects of Sun* R&D Unit, as well as projects of company.\n* Apply Machine Learning, Deep Learning to improve classic workflow.\n* Write papers about our researches and participate in international conferences.\n\nCheck out our published papers [here](https:\u002F\u002Fresearch.sun-asterisk.com\u002Fen\u002Fpublication)\n\n## Join us?\nVisit us [here](https:\u002F\u002Fresearch.sun-asterisk.com\u002Fen)",{},{},600,"png"));</script><script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/runtime.136d1f46ed0e13831702.js.download" defer=""></script><script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/content_view.7b9480c7796dcc2542c4.js.download" defer=""></script><script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/user.f8db055cc5addbe5c1fd.js.download" defer=""></script><script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/settings.9d3e8fd3a6bae05d0c8f.js.download" defer=""></script><script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/user.53e115bf07e63b6c96f3.js.download" defer=""></script><script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/user.d61fd099ac16c85a6228.js.download" defer=""></script><script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/index.0678f564d2df3141d3c4.js.download" defer=""></script><script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/survey.f6c052afb455459f7605.js.download" defer=""></script><script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/emails.c5ceecef337df1a2df63.js.download" defer=""></script><script src="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/app.6b57972a9b98a8f6b6cb.js.download" defer=""></script>
  

<link href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/settings.f3db95e19baabb5dc926.css" rel="stylesheet" type="text/css"><link href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/content_view.9764fb9e2719adb8df1a.css" rel="stylesheet" type="text/css"><div id="g_id_onload" data-client_id="321129265690-ttithr3ovvvottfro43rqr1klbf8o1co.apps.googleusercontent.com" data-login_uri="https://accounts.viblo.asia/auth/one-tap/callback?redirect_uri=https%3A%2F%2Fviblo.asia%2Fp%2Fxay-dung-he-thong-kiem-soat-nhan-dang-khuon-mat-voi-opencv-dlib-va-deep-learning-4P8566ma5Y3" data-cancel_on_tap_outside="false" data-prompt_parent_id="g_id_onload" data-moment_callback="__onOneTapContinueNextIdp" style="position: fixed; top: 45px; right: 0px; z-index: 1040;"></div><link href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/index.a708958c9fe48622d123.css" rel="stylesheet" type="text/css"><link href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/organizations.1dd77d2394bd45d95cea.css" rel="stylesheet" type="text/css"><link href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/index.614d9314499953f2515e.css" rel="stylesheet" type="text/css"><link href="./Xây dựng hệ thống kiểm soát nhận dạng khuôn mặt với OpenCV Dlib và Deep Learning_files/user.73496136fc797cdf104c.css" rel="stylesheet" type="text/css"></body></html>